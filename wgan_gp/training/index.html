
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="WGAN-GP with Meta-Feature Statistics for Synthetic Tabular Data Generation">
      
      
      
      
        <link rel="prev" href="../models/">
      
      
        <link rel="next" href="../pymfe_to_torch/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>Training - GAN_MFS Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#training-module" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="GAN_MFS Documentation" class="md-header__button md-logo" aria-label="GAN_MFS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GAN_MFS Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Training
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-blue" data-md-color-accent="blue"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../utils/" class="md-tabs__link">
        
  
  
    
  
  Utils

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  WGAN-GP

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="GAN_MFS Documentation" class="md-nav__button md-logo" aria-label="GAN_MFS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    GAN_MFS Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    WGAN-GP
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            WGAN-GP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Training
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Training
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    <span class="md-ellipsis">
      Classes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainermodified" class="md-nav__link">
    <span class="md-ellipsis">
      TrainerModified
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key Features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wgan_gp.training" class="md-nav__link">
    <span class="md-ellipsis">
      training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.sample_generator" class="md-nav__link">
    <span class="md-ellipsis">
      sample_generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.total_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      total_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified" class="md-nav__link">
    <span class="md-ellipsis">
      TrainerModified
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TrainerModified">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.calculate_mfs_torch" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_mfs_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.compute_loss_on_variates_wasserstein" class="md-nav__link">
    <span class="md-ellipsis">
      compute_loss_on_variates_wasserstein
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.plot_grad_flow" class="md-nav__link">
    <span class="md-ellipsis">
      plot_grad_flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.plot_qq_plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot_qq_plot
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.reshape_mfs_from_variates" class="md-nav__link">
    <span class="md-ellipsis">
      reshape_mfs_from_variates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.sample_from_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      sample_from_tensor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.total_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      total_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.wasserstein_distance_2d" class="md-nav__link">
    <span class="md-ellipsis">
      wasserstein_distance_2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.wasserstein_loss_mfs" class="md-nav__link">
    <span class="md-ellipsis">
      wasserstein_loss_mfs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pymfe_to_torch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PyMFE to Torch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    <span class="md-ellipsis">
      Classes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trainermodified" class="md-nav__link">
    <span class="md-ellipsis">
      TrainerModified
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key Features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wgan_gp.training" class="md-nav__link">
    <span class="md-ellipsis">
      training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.sample_generator" class="md-nav__link">
    <span class="md-ellipsis">
      sample_generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.total_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      total_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.Trainer.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified" class="md-nav__link">
    <span class="md-ellipsis">
      TrainerModified
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TrainerModified">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.calculate_mfs_torch" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_mfs_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.compute_loss_on_variates_wasserstein" class="md-nav__link">
    <span class="md-ellipsis">
      compute_loss_on_variates_wasserstein
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.plot_grad_flow" class="md-nav__link">
    <span class="md-ellipsis">
      plot_grad_flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.plot_qq_plot" class="md-nav__link">
    <span class="md-ellipsis">
      plot_qq_plot
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.reshape_mfs_from_variates" class="md-nav__link">
    <span class="md-ellipsis">
      reshape_mfs_from_variates
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.sample_from_tensor" class="md-nav__link">
    <span class="md-ellipsis">
      sample_from_tensor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.total_grad_norm" class="md-nav__link">
    <span class="md-ellipsis">
      total_grad_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.train" class="md-nav__link">
    <span class="md-ellipsis">
      train
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.wasserstein_distance_2d" class="md-nav__link">
    <span class="md-ellipsis">
      wasserstein_distance_2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.training.TrainerModified.wasserstein_loss_mfs" class="md-nav__link">
    <span class="md-ellipsis">
      wasserstein_loss_mfs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="training-module">Training Module<a class="headerlink" href="#training-module" title="Permanent link">&para;</a></h1>
<p>This module contains the core training classes for WGAN-GP with Meta-Feature Statistics (MFS) preservation.</p>
<h2 id="classes">Classes<a class="headerlink" href="#classes" title="Permanent link">&para;</a></h2>
<h3 id="trainer">Trainer<a class="headerlink" href="#trainer" title="Permanent link">&para;</a></h3>
<p>Base trainer class for vanilla WGAN-GP implementation with gradient penalty.</p>
<h3 id="trainermodified">TrainerModified<a class="headerlink" href="#trainermodified" title="Permanent link">&para;</a></h3>
<p>Enhanced trainer class that incorporates Meta-Feature Statistics preservation during training.</p>
<h2 id="key-features">Key Features<a class="headerlink" href="#key-features" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Wasserstein Distance with Gradient Penalty</strong>: Stable GAN training using WGAN-GP formulation</li>
<li><strong>Meta-Feature Statistics Preservation</strong>: Maintains statistical properties of original data</li>
<li><strong>Flexible Loss Weighting</strong>: Configurable balance between adversarial and MFS losses</li>
<li><strong>Comprehensive Monitoring</strong>: Gradient flow visualization and training metrics tracking</li>
<li><strong>Experiment Tracking</strong>: Built-in Aim integration for training progress monitoring</li>
</ul>


<div class="doc doc-object doc-module">



<h2 id="wgan_gp.training" class="doc doc-heading">
            <code>wgan_gp.training</code>


<a href="#wgan_gp.training" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">










  <div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="wgan_gp.training.Trainer" class="doc doc-heading">
            <code>Trainer</code>


<a href="#wgan_gp.training.Trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


        <p>A base class for training generative adversarial networks (GANs).</p>
<p>This class provides a basic structure for training GANs, including methods for training
the discriminator and generator, calculating gradient penalties, and generating samples.</p>








              <details class="quote">
                <summary>Source code in <code>wgan_gp/training.py</code></summary>
                <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Trainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A base class for training generative adversarial networks (GANs).</span>

<span class="sd">    This class provides a basic structure for training GANs, including methods for training</span>
<span class="sd">    the discriminator and generator, calculating gradient penalties, and generating samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">discriminator</span><span class="p">,</span>
        <span class="n">gen_optimizer</span><span class="p">,</span>
        <span class="n">dis_optimizer</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">,</span>
        <span class="n">aim_track</span><span class="p">,</span>
        <span class="n">gen_model_name</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">gp_weight</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">critic_iterations</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the WGAN-GP trainer, setting up the necessary components for adversarial training</span>
<span class="sd">        to generate synthetic data.</span>
<span class="sd">        This method prepares the generator and discriminator networks, configures their respective</span>
<span class="sd">        optimizers, and establishes the training loop parameters. It&#39;s crucial for ensuring that</span>
<span class="sd">        the GAN training process is correctly initialized, allowing the generator to learn how to</span>
<span class="sd">        create realistic synthetic samples while the discriminator learns to distinguish between</span>
<span class="sd">        real and generated data.</span>

<span class="sd">        Args:</span>
<span class="sd">            generator: The generator network.</span>
<span class="sd">            discriminator: The discriminator network.</span>
<span class="sd">            gen_optimizer: The optimizer for the generator.</span>
<span class="sd">            dis_optimizer: The optimizer for the discriminator.</span>
<span class="sd">            batch_size: The batch size for training.</span>
<span class="sd">            aim_track: A dictionary for tracking training progress with Aim.</span>
<span class="sd">            gen_model_name: The name of the generator model.</span>
<span class="sd">            disable_tqdm: Whether to disable tqdm progress bar. Defaults to False.</span>
<span class="sd">            gp_weight: The weight of the gradient penalty. Defaults to 10.</span>
<span class="sd">            critic_iterations: The number of discriminator iterations per generator iteration.</span>
<span class="sd">                Defaults to 5.</span>
<span class="sd">            device: The device to use for training (e.g., &#39;cuda&#39; or &#39;cpu&#39;).</span>
<span class="sd">                Defaults to torch.device(&#39;cpu&#39;).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span> <span class="o">=</span> <span class="n">gen_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">discriminator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_opt</span> <span class="o">=</span> <span class="n">dis_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;G&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;GP&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;gradient_norm&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp_weight</span> <span class="o">=</span> <span class="n">gp_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic_iterations</span> <span class="o">=</span> <span class="n">critic_iterations</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span> <span class="o">=</span> <span class="n">aim_track</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">disable</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="p">[</span><span class="s2">&quot;hparams&quot;</span><span class="p">]</span> <span class="o">|=</span> <span class="p">{</span><span class="s2">&quot;gen_model&quot;</span><span class="p">:</span> <span class="n">gen_model_name</span><span class="p">}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the total gradient norm of a model&#39;s parameters.</span>

<span class="sd">        Calculates the L2 norm of the gradients across all parameters in the model.</span>
<span class="sd">        This is useful for monitoring training and detecting potential issues like</span>
<span class="sd">        exploding gradients, ensuring stable training during synthetic data generation.</span>
<span class="sd">        By monitoring the gradient norm, we can ensure the generator and discriminator</span>
<span class="sd">        are learning effectively and prevent instability, which is crucial for producing</span>
<span class="sd">        high-quality synthetic data that preserves the utility of the original dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model whose gradients are to be evaluated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The total gradient norm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">total_norm</span><span class="o">**</span><span class="mf">0.5</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_critic_train_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the critic (discriminator) for one iteration to distinguish between real and</span>
<span class="sd">        generated data.</span>

<span class="sd">        The critic&#39;s objective is to maximize the difference between its output for real and</span>
<span class="sd">        generated samples, along with a gradient penalty to enforce the Lipschitz constraint.</span>
<span class="sd">        This step is crucial for improving the generator&#39;s ability to create realistic</span>
<span class="sd">        synthetic data by providing a strong adversary.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (torch.Tensor): A batch of real data samples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. The critic&#39;s loss is tracked in `self.D_loss`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># just to be explicit</span>

        <span class="c1"># Move real data to device</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>  <span class="c1"># assume self.device is torch.device(&#39;cuda&#39; or &#39;cpu&#39;)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Generate fake data</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># generator isn&#39;t trained here, so we can disable grad</span>
            <span class="n">generated_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="n">generated_data</span> <span class="o">=</span> <span class="n">generated_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Detach to be safe (in case generator outputs are connected to autograd graph)</span>
        <span class="n">generated_data</span> <span class="o">=</span> <span class="n">generated_data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="c1"># Discriminator outputs</span>
        <span class="n">d_real</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">d_generated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">generated_data</span><span class="p">)</span>

        <span class="c1"># Gradient penalty</span>
        <span class="n">gradient_penalty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_penalty</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">generated_data</span><span class="p">)</span>

        <span class="c1"># Compute WGAN-GP loss</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="n">d_generated</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">d_real</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">gradient_penalty</span>

        <span class="c1"># Backprop</span>
        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Track loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D_loss</span> <span class="o">=</span> <span class="n">d_loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generator_train_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs a single training iteration for the generator network.</span>

<span class="sd">        This involves sampling synthetic data, evaluating the generator&#39;s performance based</span>
<span class="sd">        on the discriminator&#39;s output, and updating the generator&#39;s weights to improve the</span>
<span class="sd">        quality of the generated samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (torch.Tensor): A batch of real data (not used in this function, but present</span>
<span class="sd">                for consistency with discriminator training).</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. The generator loss is stored in `self.G_loss`.</span>

<span class="sd">        Why:</span>
<span class="sd">            The generator is trained to produce synthetic data that can fool the discriminator.</span>
<span class="sd">            This function updates the generator&#39;s parameters to minimize the discriminator&#39;s</span>
<span class="sd">            ability to distinguish between real and generated data, thereby improving the</span>
<span class="sd">            realism and utility of the synthetic data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Get generated data</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">generated_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># Calculate loss and optimize</span>
        <span class="n">d_generated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">generated_data</span><span class="p">)</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">d_generated</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span> <span class="o">=</span> <span class="n">g_loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_gradient_penalty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">real_data</span><span class="p">,</span> <span class="n">generated_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradient penalty for WGAN-GP.</span>

<span class="sd">        This method calculates the gradient penalty, a regularization term used in Wasserstein</span>
<span class="sd">        GANs with gradient penalty (WGAN-GP). By penalizing the norm of discriminator gradients</span>
<span class="sd">        with respect to its input, we encourage the discriminator to have a smoother landscape.</span>
<span class="sd">        This enforces the Lipschitz constraint, which is crucial for the Wasserstein distance</span>
<span class="sd">        to be a valid metric and for stable GAN training, ultimately improving the utility of</span>
<span class="sd">        generated samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            real_data (torch.Tensor): Real data samples.</span>
<span class="sd">            generated_data (torch.Tensor): Generated data samples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The gradient penalty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">real_data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Sample interpolation factor</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">real_data</span><span class="p">)</span>

        <span class="c1"># Interpolate between real and fake data</span>
        <span class="n">interpolated</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">real_data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">generated_data</span>
        <span class="n">interpolated</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Compute critic output on interpolated data</span>
        <span class="n">prob_interpolated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">interpolated</span><span class="p">)</span>

        <span class="c1"># Compute gradients</span>
        <span class="n">grad_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">prob_interpolated</span><span class="p">)</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">torch_grad</span><span class="p">(</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">prob_interpolated</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">interpolated</span><span class="p">,</span>
            <span class="n">grad_outputs</span><span class="o">=</span><span class="n">grad_outputs</span><span class="p">,</span>
            <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">only_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gradients_norm</span> <span class="o">=</span> <span class="n">gradients</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">GP_grad_norm</span> <span class="o">=</span> <span class="n">gradients_norm</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Compute penalty</span>
        <span class="n">gp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gp_weight</span> <span class="o">*</span> <span class="p">((</span><span class="n">gradients_norm</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">gp</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the GAN for one epoch using the provided data loader, alternating between</span>
<span class="sd">        critic and generator training steps.</span>

<span class="sd">        The method iterates through the data loader, performing multiple critic updates for</span>
<span class="sd">        each generator update, as determined by `self.critic_iterations`. This ensures the</span>
<span class="sd">        critic is well-trained to differentiate between real and generated samples, which</span>
<span class="sd">        is crucial for the generator to learn to produce realistic synthetic data.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_loader: The data loader providing real data samples for training.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. The method updates the generator and critic networks in place to improve</span>
<span class="sd">            the quality and utility of generated samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span><span class="p">):</span>
            <span class="c1"># --- Critic updates ---</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic_iterations</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                    <span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure data is on the correct device</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_critic_train_iteration</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># --- Generator update ---</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure data is on the correct device</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_generator_train_iteration</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the GAN model to generate synthetic data that mimics the distribution of the real data.</span>

<span class="sd">        The training process involves iteratively updating the generator and discriminator</span>
<span class="sd">        networks to improve the quality and realism of the generated samples. The progress</span>
<span class="sd">        is monitored and visualized through loss tracking and sample plotting.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_loader: The data loader providing batches of real data for training.</span>
<span class="sd">            epochs: The number of training epochs to perform.</span>
<span class="sd">            plot_freq: The frequency (in epochs) at which to generate and plot samples to</span>
<span class="sd">                visualize training progress.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pca</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_values</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">real_data_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>

            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">real_data_sample</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">real_data_sample</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Synthetic&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Real data&quot;</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">pca</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explained var: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

            <span class="n">aim_fig</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;progress&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">GP_grad_norm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;GP_grad_norm&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
                <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates synthetic data samples using the generator network to augment the original dataset.</span>

<span class="sd">        The generated samples aim to resemble the real data distribution, enhancing the dataset&#39;s</span>
<span class="sd">        utility for downstream tasks.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_samples: The number of synthetic samples to generate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The generated synthetic data samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">latent_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">sample_latent</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">generated_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">(</span><span class="n">latent_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">generated_data</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.Trainer.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">,</span> <span class="n">gen_optimizer</span><span class="p">,</span> <span class="n">dis_optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">aim_track</span><span class="p">,</span> <span class="n">gen_model_name</span><span class="p">,</span> <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gp_weight</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">critic_iterations</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span></code>

<a href="#wgan_gp.training.Trainer.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes the WGAN-GP trainer, setting up the necessary components for adversarial training
to generate synthetic data.
This method prepares the generator and discriminator networks, configures their respective
optimizers, and establishes the training loop parameters. It's crucial for ensuring that
the GAN training process is correctly initialized, allowing the generator to learn how to
create realistic synthetic samples while the discriminator learns to distinguish between
real and generated data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>generator</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The generator network.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>discriminator</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The discriminator network.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gen_optimizer</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optimizer for the generator.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dis_optimizer</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optimizer for the discriminator.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The batch size for training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>aim_track</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary for tracking training progress with Aim.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gen_model_name</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the generator model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>disable_tqdm</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to disable tqdm progress bar. Defaults to False.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gp_weight</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The weight of the gradient penalty. Defaults to 10.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>critic_iterations</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of discriminator iterations per generator iteration.
Defaults to 5.</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The device to use for training (e.g., 'cuda' or 'cpu').
Defaults to torch.device('cpu').</p>
              </div>
            </td>
            <td>
                  <code><span title="torch.device">device</span>(&#39;cpu&#39;)</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">discriminator</span><span class="p">,</span>
    <span class="n">gen_optimizer</span><span class="p">,</span>
    <span class="n">dis_optimizer</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">aim_track</span><span class="p">,</span>
    <span class="n">gen_model_name</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">gp_weight</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">critic_iterations</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the WGAN-GP trainer, setting up the necessary components for adversarial training</span>
<span class="sd">    to generate synthetic data.</span>
<span class="sd">    This method prepares the generator and discriminator networks, configures their respective</span>
<span class="sd">    optimizers, and establishes the training loop parameters. It&#39;s crucial for ensuring that</span>
<span class="sd">    the GAN training process is correctly initialized, allowing the generator to learn how to</span>
<span class="sd">    create realistic synthetic samples while the discriminator learns to distinguish between</span>
<span class="sd">    real and generated data.</span>

<span class="sd">    Args:</span>
<span class="sd">        generator: The generator network.</span>
<span class="sd">        discriminator: The discriminator network.</span>
<span class="sd">        gen_optimizer: The optimizer for the generator.</span>
<span class="sd">        dis_optimizer: The optimizer for the discriminator.</span>
<span class="sd">        batch_size: The batch size for training.</span>
<span class="sd">        aim_track: A dictionary for tracking training progress with Aim.</span>
<span class="sd">        gen_model_name: The name of the generator model.</span>
<span class="sd">        disable_tqdm: Whether to disable tqdm progress bar. Defaults to False.</span>
<span class="sd">        gp_weight: The weight of the gradient penalty. Defaults to 10.</span>
<span class="sd">        critic_iterations: The number of discriminator iterations per generator iteration.</span>
<span class="sd">            Defaults to 5.</span>
<span class="sd">        device: The device to use for training (e.g., &#39;cuda&#39; or &#39;cpu&#39;).</span>
<span class="sd">            Defaults to torch.device(&#39;cpu&#39;).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="n">generator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span> <span class="o">=</span> <span class="n">gen_optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">discriminator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">D_opt</span> <span class="o">=</span> <span class="n">dis_optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;G&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;GP&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;gradient_norm&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gp_weight</span> <span class="o">=</span> <span class="n">gp_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">critic_iterations</span> <span class="o">=</span> <span class="n">critic_iterations</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span> <span class="o">=</span> <span class="n">aim_track</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">disable</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="p">[</span><span class="s2">&quot;hparams&quot;</span><span class="p">]</span> <span class="o">|=</span> <span class="p">{</span><span class="s2">&quot;gen_model&quot;</span><span class="p">:</span> <span class="n">gen_model_name</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.Trainer.sample_generator" class="doc doc-heading">
            <code class=" language-python"><span class="n">sample_generator</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span></code>

<a href="#wgan_gp.training.Trainer.sample_generator" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Generates synthetic data samples using the generator network to augment the original dataset.</p>
<p>The generated samples aim to resemble the real data distribution, enhancing the dataset's
utility for downstream tasks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_samples</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of synthetic samples to generate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The generated synthetic data samples.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates synthetic data samples using the generator network to augment the original dataset.</span>

<span class="sd">    The generated samples aim to resemble the real data distribution, enhancing the dataset&#39;s</span>
<span class="sd">    utility for downstream tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_samples: The number of synthetic samples to generate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The generated synthetic data samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">latent_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">sample_latent</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">generated_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">(</span><span class="n">latent_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">generated_data</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.Trainer.total_grad_norm" class="doc doc-heading">
            <code class=" language-python"><span class="n">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.training.Trainer.total_grad_norm" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the total gradient norm of a model's parameters.</p>
<p>Calculates the L2 norm of the gradients across all parameters in the model.
This is useful for monitoring training and detecting potential issues like
exploding gradients, ensuring stable training during synthetic data generation.
By monitoring the gradient norm, we can ensure the generator and discriminator
are learning effectively and prevent instability, which is crucial for producing
high-quality synthetic data that preserves the utility of the original dataset.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model whose gradients are to be evaluated.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>float</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The total gradient norm.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the total gradient norm of a model&#39;s parameters.</span>

<span class="sd">    Calculates the L2 norm of the gradients across all parameters in the model.</span>
<span class="sd">    This is useful for monitoring training and detecting potential issues like</span>
<span class="sd">    exploding gradients, ensuring stable training during synthetic data generation.</span>
<span class="sd">    By monitoring the gradient norm, we can ensure the generator and discriminator</span>
<span class="sd">    are learning effectively and prevent instability, which is crucial for producing</span>
<span class="sd">    high-quality synthetic data that preserves the utility of the original dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The model whose gradients are to be evaluated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The total gradient norm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">total_norm</span><span class="o">**</span><span class="mf">0.5</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.Trainer.train" class="doc doc-heading">
            <code class=" language-python"><span class="n">train</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">)</span></code>

<a href="#wgan_gp.training.Trainer.train" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Trains the GAN model to generate synthetic data that mimics the distribution of the real data.</p>
<p>The training process involves iteratively updating the generator and discriminator
networks to improve the quality and realism of the generated samples. The progress
is monitored and visualized through loss tracking and sample plotting.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>data_loader</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data loader providing batches of real data for training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epochs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of training epochs to perform.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>plot_freq</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The frequency (in epochs) at which to generate and plot samples to
visualize training progress.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains the GAN model to generate synthetic data that mimics the distribution of the real data.</span>

<span class="sd">    The training process involves iteratively updating the generator and discriminator</span>
<span class="sd">    networks to improve the quality and realism of the generated samples. The progress</span>
<span class="sd">    is monitored and visualized through loss tracking and sample plotting.</span>

<span class="sd">    Args:</span>
<span class="sd">        data_loader: The data loader providing batches of real data for training.</span>
<span class="sd">        epochs: The number of training epochs to perform.</span>
<span class="sd">        plot_freq: The frequency (in epochs) at which to generate and plot samples to</span>
<span class="sd">            visualize training progress.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_values</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">real_data_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>

        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">real_data_sample</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">real_data_sample</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Synthetic&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Real data&quot;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">pca</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explained var: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="n">aim_fig</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;progress&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">GP_grad_norm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;GP_grad_norm&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="wgan_gp.training.TrainerModified" class="doc doc-heading">
            <code>TrainerModified</code>


<a href="#wgan_gp.training.TrainerModified" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="Trainer (wgan_gp.training.Trainer)" href="#wgan_gp.training.Trainer">Trainer</a></code></p>


        <p>A modified trainer class for training GANs with Meta-Feature Statistics (MFS) preservation.</p>
<p>This class extends the base trainer to incorporate Meta-Feature Statistics (MFS)
into the training process, allowing for targeted preservation of statistical properties
and enhanced synthetic data quality.</p>








              <details class="quote">
                <summary>Source code in <code>wgan_gp/training.py</code></summary>
                <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TrainerModified</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A modified trainer class for training GANs with Meta-Feature Statistics (MFS) preservation.</span>

<span class="sd">    This class extends the base trainer to incorporate Meta-Feature Statistics (MFS)</span>
<span class="sd">    into the training process, allowing for targeted preservation of statistical properties</span>
<span class="sd">    and enhanced synthetic data quality.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs_lambda</span><span class="p">,</span> <span class="n">subset_mfs</span><span class="p">,</span> <span class="n">target_mfs</span><span class="p">,</span> <span class="n">sample_number</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the TrainerModified class with Meta-Feature Statistics preservation.</span>

<span class="sd">        This class configures the training process for the GAN, focusing on preserving</span>
<span class="sd">        meta-feature statistics to enhance the utility of generated synthetic data. It sets up</span>
<span class="sd">        the parameters that guide the MFS preservation process, ensuring the generated data</span>
<span class="sd">        retains key statistical characteristics of the real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            mfs_lambda (float or list): Lambda value(s) for MFS loss weighting, controlling</span>
<span class="sd">                the strength of the meta-feature preservation regularization.</span>
<span class="sd">            subset_mfs (list): Subset of meta-features to preserve, defining which statistical</span>
<span class="sd">                properties to focus on during training.</span>
<span class="sd">            target_mfs (dict): Target MFS distributions, specifying the desired meta-feature</span>
<span class="sd">                distributions in the generated data. Defaults to {&quot;other_mfs&quot;: 0} if not provided.</span>
<span class="sd">            sample_number (int): Number of variates to use during MFS calculation, influencing</span>
<span class="sd">                the stability and accuracy of meta-feature estimation.</span>
<span class="sd">            **kwargs: Additional keyword arguments passed to the parent Trainer class.</span>

<span class="sd">        The method initializes the training process by setting up the meta-feature statistics (MFS)</span>
<span class="sd">        parameters. This setup is crucial for guiding the GAN to generate synthetic data that not</span>
<span class="sd">        only resembles the real data visually but also maintains its statistical utility. The</span>
<span class="sd">        target_mfs parameter allows specifying the desired distribution of meta-features in the</span>
<span class="sd">        generated data, ensuring that the synthetic data preserves important statistical properties</span>
<span class="sd">        for downstream tasks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TrainerModified</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span> <span class="o">=</span> <span class="n">mfs_lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subset_mfs</span> <span class="o">=</span> <span class="n">subset_mfs</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">target_mfs</span><span class="p">:</span>
            <span class="n">target_mfs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span> <span class="o">=</span> <span class="n">target_mfs</span>

        <span class="k">if</span> <span class="s2">&quot;other_mfs&quot;</span> <span class="ow">in</span> <span class="n">target_mfs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span> <span class="o">=</span> <span class="n">MFEToTorch</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_dist_func</span> <span class="o">=</span> <span class="n">WassersteinDistance</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_number</span> <span class="o">=</span> <span class="n">sample_number</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_from_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples a subset of data points from a given tensor.</span>

<span class="sd">        This is useful for creating smaller, representative datasets for tasks such as</span>
<span class="sd">        evaluating model performance on a subset of the data or for visualization purposes.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor): The input tensor from which to sample.</span>
<span class="sd">            n_samples (int): The number of data points to sample from the tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A new tensor containing the sampled data points.</span>
<span class="sd">                The sampled data maintains the original data&#39;s structure while reducing its size,</span>
<span class="sd">                which is important for efficient analysis and evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">indices_trunc</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
        <span class="n">sampled_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">indices_trunc</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">sampled_tensor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_mfs_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the meta-feature statistics (MFS) to quantify statistical properties for</span>
<span class="sd">        preserving data utility in GAN-generated synthetic data.</span>

<span class="sd">        This method leverages the MFS manager to assess various statistical properties of the</span>
<span class="sd">        input tensor X, optionally conditioned on a target tensor y. This helps in understanding</span>
<span class="sd">        which statistical characteristics are most important for preserving data utility in</span>
<span class="sd">        synthetic samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (torch.Tensor): The input tensor representing the synthetic data features.</span>
<span class="sd">            y (torch.Tensor, optional): The target tensor representing the corresponding</span>
<span class="sd">                target variable. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The calculated MFS values, moved to the specified device.</span>
<span class="sd">                These values represent various statistical properties of the data (correlation,</span>
<span class="sd">                covariance, eigenvalues, etc.), which are used to guide the generator&#39;s</span>
<span class="sd">                learning process and ensure statistical fidelity.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span><span class="o">.</span><span class="n">get_mfs</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">subset_mfs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the total gradient norm of a model&#39;s parameters.</span>

<span class="sd">        Calculates the L2 norm of the gradients across all parameters in the model.</span>
<span class="sd">        This is useful for monitoring training and detecting potential issues like</span>
<span class="sd">        exploding gradients, ensuring stable training during synthetic data generation.</span>
<span class="sd">        By monitoring the gradient norm, we can ensure the generator and discriminator</span>
<span class="sd">        are learning effectively and preventing mode collapse, which is crucial for</span>
<span class="sd">        producing high-quality synthetic data.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The model whose gradients are to be analyzed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The total gradient norm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">total_norm</span><span class="o">**</span><span class="mf">0.5</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss_on_variates_wasserstein</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fake_distribution</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the Wasserstein loss to align generated and real data distributions.</span>

<span class="sd">        This method calculates the Wasserstein distance between the target meta-feature</span>
<span class="sd">        statistics (MFS) and the MFS generated from the fake data distribution. It first</span>
<span class="sd">        calculates the MFS for each variate in the fake distribution, reshapes them, and</span>
<span class="sd">        then computes the Wasserstein distance using the specified distance function. This</span>
<span class="sd">        loss encourages the generator to produce data with similar statistical properties</span>
<span class="sd">        to the real data, enhancing the utility of the synthetic data for downstream tasks.</span>

<span class="sd">        Args:</span>
<span class="sd">            fake_distribution: A list of tensors representing the generated data distribution.</span>
<span class="sd">                Each tensor represents a variate.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The Wasserstein distance between the target MFS and the generated MFS.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fake_mfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">calculate_mfs_torch</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">fake_distribution</span><span class="p">]</span>
        <span class="n">fake_mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">fake_mfs</span><span class="p">)</span>

        <span class="c1"># mfs_to_track = fake_mfs.clone()</span>
        <span class="c1"># self.mfs_to_track = mfs_to_track.mean(dim=1).cpu().detach().numpy().round(5).tolist()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_dist_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">fake_mfs</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">mfs_from_variates</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reshapes a list of meta-feature statistics from variates into a tensor for comparison.</span>

<span class="sd">        The input list `mfs_from_variates` contains MFS values, which are stacked</span>
<span class="sd">        and then transposed to create the reshaped tensor. This reshaping</span>
<span class="sd">        facilitates the calculation of metrics and topological analysis</span>
<span class="sd">        needed to evaluate the quality and utility of the generated synthetic data.</span>

<span class="sd">        Args:</span>
<span class="sd">            mfs_from_variates: A list of meta-feature statistics from variates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A reshaped tensor where the first dimension corresponds</span>
<span class="sd">                to the variates and the second dimension corresponds to the MFS values.</span>
<span class="sd">                This format is required for subsequent analysis and comparison</span>
<span class="sd">                of real and synthetic data characteristics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">mfs_from_variates</span><span class="p">)</span>
        <span class="n">reshaped</span> <span class="o">=</span> <span class="n">stacked</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reshaped</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wasserstein_distance_2d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Wasserstein distance between two 2D point clouds.</span>

<span class="sd">        This method calculates the Earth Mover&#39;s Distance (EMD), also known as the</span>
<span class="sd">        Wasserstein distance, between two sets of 2D points. It assumes that both</span>
<span class="sd">        point clouds have equal weights assigned to each point. This distance is used</span>
<span class="sd">        to evaluate how well the generated data distribution matches the real data</span>
<span class="sd">        distribution, ensuring the synthetic data retains statistical similarity.</span>

<span class="sd">        Args:</span>
<span class="sd">            x1 (torch.Tensor): The first point cloud, represented as a batch of 2D points.</span>
<span class="sd">            x2 (torch.Tensor): The second point cloud, represented as a batch of 2D points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Wasserstein distance between the two point clouds.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">ab</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>
        <span class="n">ab</span> <span class="o">=</span> <span class="n">ab</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ot</span><span class="o">.</span><span class="n">emd2</span><span class="p">(</span><span class="n">ab</span><span class="p">,</span> <span class="n">ab</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wasserstein_loss_mfs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs1</span><span class="p">,</span> <span class="n">mfs2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the Wasserstein loss between two sets of meta-feature statistics (MFS).</span>

<span class="sd">        This method quantifies the statistical similarity between the real and synthetic</span>
<span class="sd">        data distributions by computing the Wasserstein distance between corresponding</span>
<span class="sd">        feature pairs in the input MFS sets. This loss is used to train the generator</span>
<span class="sd">        to produce synthetic data that closely matches the statistical properties of</span>
<span class="sd">        the real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            mfs1 (torch.Tensor): The first set of meta-feature statistics, representing</span>
<span class="sd">                the real data distribution.</span>
<span class="sd">            mfs2 (torch.Tensor): The second set of meta-feature statistics, representing</span>
<span class="sd">                the synthetic data distribution.</span>
<span class="sd">            average (bool, optional): A boolean indicating whether to return the average</span>
<span class="sd">                loss (True) or a tensor of individual losses (False). Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor or float: If `average` is True, returns the average</span>
<span class="sd">                Wasserstein loss as a float. Otherwise, returns a tensor containing the</span>
<span class="sd">                individual Wasserstein distances for each feature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># total = 0</span>
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">mfs1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">wsds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mfs1</span><span class="p">,</span> <span class="n">mfs2</span><span class="p">):</span>
            <span class="n">wsd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_distance_2d</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">second</span><span class="p">)</span>
            <span class="n">wsds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wsd</span><span class="p">)</span>
            <span class="c1"># total += wsd</span>

        <span class="c1"># print_debug = [[i, j.cpu().detach()] for i, j in zip(self.subset_mfs, wsds)]</span>
        <span class="c1"># print(*print_debug,</span>
        <span class="c1">#       sep=&#39;\n&#39;)</span>
        <span class="k">if</span> <span class="n">average</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">wsds</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">wsds</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generator_train_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates synthetic data in one training step and optimizes the generator network.</span>

<span class="sd">        This method produces data that is indistinguishable from real data based on the</span>
<span class="sd">        discriminator&#39;s feedback and the matching of meta-feature statistics. The generator</span>
<span class="sd">        is optimized to minimize both adversarial loss and MFS preservation loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (torch.Tensor): A batch of real data used to determine batch size.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. The generator&#39;s parameters are updated to minimize the combined adversarial</span>
<span class="sd">                and meta-feature statistics loss. The losses are also recorded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Get generated data</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">generated_variates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_number</span><span class="p">):</span>
            <span class="n">generated_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

            <span class="n">generated_data</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">generated_data</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span>

            <span class="c1"># generated_data = generated_data.to(self.device)</span>
            <span class="n">generated_variates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">generated_data</span><span class="p">)</span>

        <span class="c1"># Calculate loss and optimize</span>
        <span class="n">d_generated</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">generated_variates</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">fake_mfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">calculate_mfs_torch</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">generated_variates</span><span class="p">]</span>
        <span class="n">fake_mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">fake_mfs</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">mfs_lambda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">mfs_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_loss_mfs</span><span class="p">(</span>
                <span class="n">fake_mfs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

            <span class="n">loss_mfs</span> <span class="o">=</span> <span class="n">mfs_lambda</span> <span class="o">@</span> <span class="n">mfs_dist</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">mfs_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_loss_mfs</span><span class="p">(</span>
                <span class="n">fake_mfs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">loss_mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span> <span class="o">*</span> <span class="n">mfs_dist</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;mfs_lambda must be either a list or a float&quot;</span><span class="p">)</span>

        <span class="n">g_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">d_generated</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">loss_mfs</span>

        <span class="k">if</span> <span class="n">PLOT_GRAPH</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s2">&quot;mod_computation_graph_G_loss.png&quot;</span><span class="p">):</span>
                <span class="n">make_dot</span><span class="p">(</span><span class="n">g_loss</span><span class="p">,</span> <span class="n">show_attrs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                    <span class="s2">&quot;mod_computation_graph_G_loss&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span>
                <span class="p">)</span>

        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Record loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span> <span class="o">=</span> <span class="n">g_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mfs_loss</span> <span class="o">=</span> <span class="n">loss_mfs</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_grad_flow</span><span class="p">(</span><span class="n">named_parameters</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Gradient flow&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the gradient flow through the layers of a neural network to assess training dynamics.</span>

<span class="sd">        This method calculates and visualizes the average gradient magnitude</span>
<span class="sd">        for each layer of the network, excluding bias parameters. By observing the gradient flow,</span>
<span class="sd">        one can identify layers that might be hindering the learning process due to vanishing</span>
<span class="sd">        or exploding gradients, ensuring stable and effective training by maintaining data utility.</span>

<span class="sd">        Args:</span>
<span class="sd">            named_parameters: An iterator of tuples containing layer names and</span>
<span class="sd">                parameter tensors.</span>
<span class="sd">            title: The title of the plot. Defaults to &quot;Gradient flow&quot;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            matplotlib.figure.Figure: A matplotlib figure containing the gradient flow plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ave_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">named_parameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
                <span class="n">ave_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)),</span> <span class="n">layers</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Layer&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Avg Gradient Magnitude&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_qq_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs_batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots a quantile-quantile (QQ) plot to compare MFS distributions.</span>

<span class="sd">        This method generates a QQ plot to visually assess how well the generated MFS from</span>
<span class="sd">        a batch matches the distribution of the target MFS. It also plots a histogram of the</span>
<span class="sd">        target MFS to visualize its distribution. The QQ plot helps determine if the GAN is</span>
<span class="sd">        effectively learning to reproduce the statistical properties of the real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            mfs_batch: A batch of generated MFS to compare against the target distribution.</span>

<span class="sd">        Returns:</span>
<span class="sd">            matplotlib.figure.Figure: The matplotlib figure containing the QQ plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detached_target</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">mfs_batch_</span> <span class="o">=</span> <span class="n">mfs_batch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">detached_target</span><span class="p">)</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot_2samples</span><span class="p">(</span><span class="n">data1</span><span class="o">=</span><span class="n">detached_target</span><span class="p">,</span> <span class="n">data2</span><span class="o">=</span><span class="n">mfs_batch_</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the GAN model to generate synthetic data that mimics the statistical properties of the real data.</span>

<span class="sd">        The training process involves updating the generator and discriminator networks iteratively</span>
<span class="sd">        to improve the quality and utility of the generated samples. The method also tracks</span>
<span class="sd">        various metrics and visualizations to monitor the training progress and evaluate the</span>
<span class="sd">        performance of the GAN.</span>

<span class="sd">        Args:</span>
<span class="sd">            data_loader: The data loader providing batches of real data for training.</span>
<span class="sd">            epochs: The number of training epochs to perform.</span>
<span class="sd">            plot_freq: The frequency (in epochs) at which to generate and track plots for</span>
<span class="sd">                monitoring training progress.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None. The method trains the GAN model in place, updating the generator and</span>
<span class="sd">                discriminator networks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pca</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span><span class="o">.</span><span class="n">change_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_values</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">real_data_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>
            <span class="c1"># samples = [self.sample_generator(self.batch_size) for _ in range(self.sample_number)]</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mfs_loss</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss MFS&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">GP_grad_norm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;GP_grad_norm&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">pca</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                    <span class="n">samples</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">real_data_sample</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">real_data_sample</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

                <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Synthetic&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Real data&quot;</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">pca</span><span class="p">:</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explained var: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

                <span class="n">aim_fig</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;progress&quot;</span><span class="p">)</span>
                <span class="c1"># fig = plt.figure()</span>
                <span class="c1"># plt.scatter(samples[0].cpu().detach().numpy()[:, 0], samples[0].cpu().detach().numpy()[:, 1],</span>
                <span class="c1">#             label=&quot;Synthetic&quot;, alpha=0.2)</span>
                <span class="c1"># plt.scatter(real_data_sample[:, 0], real_data_sample[:, 1],</span>
                <span class="c1">#             label=&quot;Real data&quot;, alpha=0.2)</span>
                <span class="c1">#</span>
                <span class="c1"># plt.legend()</span>
                <span class="c1"># plt.close(fig)</span>

                <span class="c1"># aim_fig = Image(fig)</span>
                <span class="c1"># self.aim_track.track(aim_fig, epoch=epoch, name=&quot;progress&quot;)</span>

                <span class="n">fig_G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_grad_flow</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;G gradient flow&quot;</span>
                <span class="p">)</span>
                <span class="n">fig_D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_grad_flow</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;D gradient flow&quot;</span>
                <span class="p">)</span>

                <span class="c1"># fig_mfs_distr = self.plot_qq_plot(</span>
                <span class="c1">#     mfs_batch=np.asarray([self.calculate_mfs_torch(X).cpu().detach().numpy() for X in samples]))</span>

                <span class="n">aim_fig_G</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig_G</span><span class="p">)</span>
                <span class="n">aim_fig_D</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig_D</span><span class="p">)</span>
                <span class="c1"># aim_fig_mfs_distr = Image(fig_mfs_distr)</span>

                <span class="c1"># self.aim_track.track(aim_fig_mfs_distr, epoch=epoch, name=&quot;qq plot&quot;)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig_G</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;G grad flow&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig_D</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;D grad flow&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">mfs_lambda</span><span class="p">,</span> <span class="n">subset_mfs</span><span class="p">,</span> <span class="n">target_mfs</span><span class="p">,</span> <span class="n">sample_number</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Initializes the TrainerModified class with Meta-Feature Statistics preservation.</p>
<p>This class configures the training process for the GAN, focusing on preserving
meta-feature statistics to enhance the utility of generated synthetic data. It sets up
the parameters that guide the MFS preservation process, ensuring the generated data
retains key statistical characteristics of the real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mfs_lambda</code>
            </td>
            <td>
                  <code><span title="float">float</span> or <span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lambda value(s) for MFS loss weighting, controlling
the strength of the meta-feature preservation regularization.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>subset_mfs</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Subset of meta-features to preserve, defining which statistical
properties to focus on during training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target_mfs</code>
            </td>
            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target MFS distributions, specifying the desired meta-feature
distributions in the generated data. Defaults to {"other_mfs": 0} if not provided.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_number</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of variates to use during MFS calculation, influencing
the stability and accuracy of meta-feature estimation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional keyword arguments passed to the parent Trainer class.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>The method initializes the training process by setting up the meta-feature statistics (MFS)
parameters. This setup is crucial for guiding the GAN to generate synthetic data that not
only resembles the real data visually but also maintains its statistical utility. The
target_mfs parameter allows specifying the desired distribution of meta-features in the
generated data, ensuring that the synthetic data preserves important statistical properties
for downstream tasks.</p>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs_lambda</span><span class="p">,</span> <span class="n">subset_mfs</span><span class="p">,</span> <span class="n">target_mfs</span><span class="p">,</span> <span class="n">sample_number</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the TrainerModified class with Meta-Feature Statistics preservation.</span>

<span class="sd">    This class configures the training process for the GAN, focusing on preserving</span>
<span class="sd">    meta-feature statistics to enhance the utility of generated synthetic data. It sets up</span>
<span class="sd">    the parameters that guide the MFS preservation process, ensuring the generated data</span>
<span class="sd">    retains key statistical characteristics of the real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        mfs_lambda (float or list): Lambda value(s) for MFS loss weighting, controlling</span>
<span class="sd">            the strength of the meta-feature preservation regularization.</span>
<span class="sd">        subset_mfs (list): Subset of meta-features to preserve, defining which statistical</span>
<span class="sd">            properties to focus on during training.</span>
<span class="sd">        target_mfs (dict): Target MFS distributions, specifying the desired meta-feature</span>
<span class="sd">            distributions in the generated data. Defaults to {&quot;other_mfs&quot;: 0} if not provided.</span>
<span class="sd">        sample_number (int): Number of variates to use during MFS calculation, influencing</span>
<span class="sd">            the stability and accuracy of meta-feature estimation.</span>
<span class="sd">        **kwargs: Additional keyword arguments passed to the parent Trainer class.</span>

<span class="sd">    The method initializes the training process by setting up the meta-feature statistics (MFS)</span>
<span class="sd">    parameters. This setup is crucial for guiding the GAN to generate synthetic data that not</span>
<span class="sd">    only resembles the real data visually but also maintains its statistical utility. The</span>
<span class="sd">    target_mfs parameter allows specifying the desired distribution of meta-features in the</span>
<span class="sd">    generated data, ensuring that the synthetic data preserves important statistical properties</span>
<span class="sd">    for downstream tasks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TrainerModified</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mfs_lambda</span> <span class="o">=</span> <span class="n">mfs_lambda</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">subset_mfs</span> <span class="o">=</span> <span class="n">subset_mfs</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">target_mfs</span><span class="p">:</span>
        <span class="n">target_mfs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span> <span class="o">=</span> <span class="n">target_mfs</span>

    <span class="k">if</span> <span class="s2">&quot;other_mfs&quot;</span> <span class="ow">in</span> <span class="n">target_mfs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span> <span class="o">=</span> <span class="n">MFEToTorch</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_dist_func</span> <span class="o">=</span> <span class="n">WassersteinDistance</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_number</span> <span class="o">=</span> <span class="n">sample_number</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.calculate_mfs_torch" class="doc doc-heading">
            <code class=" language-python"><span class="n">calculate_mfs_torch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.calculate_mfs_torch" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the meta-feature statistics (MFS) to quantify statistical properties for
preserving data utility in GAN-generated synthetic data.</p>
<p>This method leverages the MFS manager to assess various statistical properties of the
input tensor X, optionally conditioned on a target tensor y. This helps in understanding
which statistical characteristics are most important for preserving data utility in
synthetic samples.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor representing the synthetic data features.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target tensor representing the corresponding
target variable. Defaults to None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The calculated MFS values, moved to the specified device.
These values represent various statistical properties of the data (correlation,
covariance, eigenvalues, etc.), which are used to guide the generator's
learning process and ensure statistical fidelity.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mfs_torch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the meta-feature statistics (MFS) to quantify statistical properties for</span>
<span class="sd">    preserving data utility in GAN-generated synthetic data.</span>

<span class="sd">    This method leverages the MFS manager to assess various statistical properties of the</span>
<span class="sd">    input tensor X, optionally conditioned on a target tensor y. This helps in understanding</span>
<span class="sd">    which statistical characteristics are most important for preserving data utility in</span>
<span class="sd">    synthetic samples.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (torch.Tensor): The input tensor representing the synthetic data features.</span>
<span class="sd">        y (torch.Tensor, optional): The target tensor representing the corresponding</span>
<span class="sd">            target variable. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The calculated MFS values, moved to the specified device.</span>
<span class="sd">            These values represent various statistical properties of the data (correlation,</span>
<span class="sd">            covariance, eigenvalues, etc.), which are used to guide the generator&#39;s</span>
<span class="sd">            learning process and ensure statistical fidelity.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span><span class="o">.</span><span class="n">get_mfs</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">subset_mfs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.compute_loss_on_variates_wasserstein" class="doc doc-heading">
            <code class=" language-python"><span class="n">compute_loss_on_variates_wasserstein</span><span class="p">(</span><span class="n">fake_distribution</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.compute_loss_on_variates_wasserstein" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the Wasserstein loss to align generated and real data distributions.</p>
<p>This method calculates the Wasserstein distance between the target meta-feature
statistics (MFS) and the MFS generated from the fake data distribution. It first
calculates the MFS for each variate in the fake distribution, reshapes them, and
then computes the Wasserstein distance using the specified distance function. This
loss encourages the generator to produce data with similar statistical properties
to the real data, enhancing the utility of the synthetic data for downstream tasks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>fake_distribution</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of tensors representing the generated data distribution.
Each tensor represents a variate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The Wasserstein distance between the target MFS and the generated MFS.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_loss_on_variates_wasserstein</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fake_distribution</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Wasserstein loss to align generated and real data distributions.</span>

<span class="sd">    This method calculates the Wasserstein distance between the target meta-feature</span>
<span class="sd">    statistics (MFS) and the MFS generated from the fake data distribution. It first</span>
<span class="sd">    calculates the MFS for each variate in the fake distribution, reshapes them, and</span>
<span class="sd">    then computes the Wasserstein distance using the specified distance function. This</span>
<span class="sd">    loss encourages the generator to produce data with similar statistical properties</span>
<span class="sd">    to the real data, enhancing the utility of the synthetic data for downstream tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        fake_distribution: A list of tensors representing the generated data distribution.</span>
<span class="sd">            Each tensor represents a variate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The Wasserstein distance between the target MFS and the generated MFS.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fake_mfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">calculate_mfs_torch</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">fake_distribution</span><span class="p">]</span>
    <span class="n">fake_mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">fake_mfs</span><span class="p">)</span>

    <span class="c1"># mfs_to_track = fake_mfs.clone()</span>
    <span class="c1"># self.mfs_to_track = mfs_to_track.mean(dim=1).cpu().detach().numpy().round(5).tolist()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_dist_func</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">],</span> <span class="n">fake_mfs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.plot_grad_flow" class="doc doc-heading">
            <code class=" language-python"><span class="n">plot_grad_flow</span><span class="p">(</span><span class="n">named_parameters</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Gradient flow&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.training.TrainerModified.plot_grad_flow" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Plots the gradient flow through the layers of a neural network to assess training dynamics.</p>
<p>This method calculates and visualizes the average gradient magnitude
for each layer of the network, excluding bias parameters. By observing the gradient flow,
one can identify layers that might be hindering the learning process due to vanishing
or exploding gradients, ensuring stable and effective training by maintaining data utility.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>named_parameters</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An iterator of tuples containing layer names and
parameter tensors.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>title</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The title of the plot. Defaults to "Gradient flow".</p>
              </div>
            </td>
            <td>
                  <code>&#39;Gradient flow&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>matplotlib.figure.Figure: A matplotlib figure containing the gradient flow plot.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_grad_flow</span><span class="p">(</span><span class="n">named_parameters</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Gradient flow&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the gradient flow through the layers of a neural network to assess training dynamics.</span>

<span class="sd">    This method calculates and visualizes the average gradient magnitude</span>
<span class="sd">    for each layer of the network, excluding bias parameters. By observing the gradient flow,</span>
<span class="sd">    one can identify layers that might be hindering the learning process due to vanishing</span>
<span class="sd">    or exploding gradients, ensuring stable and effective training by maintaining data utility.</span>

<span class="sd">    Args:</span>
<span class="sd">        named_parameters: An iterator of tuples containing layer names and</span>
<span class="sd">            parameter tensors.</span>
<span class="sd">        title: The title of the plot. Defaults to &quot;Gradient flow&quot;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        matplotlib.figure.Figure: A matplotlib figure containing the gradient flow plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ave_grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">named_parameters</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="n">ave_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ave_grads</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)),</span> <span class="n">layers</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s2">&quot;vertical&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Layer&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Avg Gradient Magnitude&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.plot_qq_plot" class="doc doc-heading">
            <code class=" language-python"><span class="n">plot_qq_plot</span><span class="p">(</span><span class="n">mfs_batch</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.plot_qq_plot" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Plots a quantile-quantile (QQ) plot to compare MFS distributions.</p>
<p>This method generates a QQ plot to visually assess how well the generated MFS from
a batch matches the distribution of the target MFS. It also plots a histogram of the
target MFS to visualize its distribution. The QQ plot helps determine if the GAN is
effectively learning to reproduce the statistical properties of the real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mfs_batch</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A batch of generated MFS to compare against the target distribution.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>matplotlib.figure.Figure: The matplotlib figure containing the QQ plot.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_qq_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs_batch</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots a quantile-quantile (QQ) plot to compare MFS distributions.</span>

<span class="sd">    This method generates a QQ plot to visually assess how well the generated MFS from</span>
<span class="sd">    a batch matches the distribution of the target MFS. It also plots a histogram of the</span>
<span class="sd">    target MFS to visualize its distribution. The QQ plot helps determine if the GAN is</span>
<span class="sd">    effectively learning to reproduce the statistical properties of the real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        mfs_batch: A batch of generated MFS to compare against the target distribution.</span>

<span class="sd">    Returns:</span>
<span class="sd">        matplotlib.figure.Figure: The matplotlib figure containing the QQ plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">detached_target</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_mfs</span><span class="p">[</span><span class="s2">&quot;other_mfs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">mfs_batch_</span> <span class="o">=</span> <span class="n">mfs_batch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">detached_target</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot_2samples</span><span class="p">(</span><span class="n">data1</span><span class="o">=</span><span class="n">detached_target</span><span class="p">,</span> <span class="n">data2</span><span class="o">=</span><span class="n">mfs_batch_</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.reshape_mfs_from_variates" class="doc doc-heading">
            <code class=" language-python"><span class="n">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">mfs_from_variates</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.training.TrainerModified.reshape_mfs_from_variates" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Reshapes a list of meta-feature statistics from variates into a tensor for comparison.</p>
<p>The input list <code>mfs_from_variates</code> contains MFS values, which are stacked
and then transposed to create the reshaped tensor. This reshaping
facilitates the calculation of metrics and topological analysis
needed to evaluate the quality and utility of the generated synthetic data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mfs_from_variates</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of meta-feature statistics from variates.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A reshaped tensor where the first dimension corresponds
to the variates and the second dimension corresponds to the MFS values.
This format is required for subsequent analysis and comparison
of real and synthetic data characteristics.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">reshape_mfs_from_variates</span><span class="p">(</span><span class="n">mfs_from_variates</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reshapes a list of meta-feature statistics from variates into a tensor for comparison.</span>

<span class="sd">    The input list `mfs_from_variates` contains MFS values, which are stacked</span>
<span class="sd">    and then transposed to create the reshaped tensor. This reshaping</span>
<span class="sd">    facilitates the calculation of metrics and topological analysis</span>
<span class="sd">    needed to evaluate the quality and utility of the generated synthetic data.</span>

<span class="sd">    Args:</span>
<span class="sd">        mfs_from_variates: A list of meta-feature statistics from variates.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A reshaped tensor where the first dimension corresponds</span>
<span class="sd">            to the variates and the second dimension corresponds to the MFS values.</span>
<span class="sd">            This format is required for subsequent analysis and comparison</span>
<span class="sd">            of real and synthetic data characteristics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">mfs_from_variates</span><span class="p">)</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">stacked</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">reshaped</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.sample_from_tensor" class="doc doc-heading">
            <code class=" language-python"><span class="n">sample_from_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.training.TrainerModified.sample_from_tensor" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Samples a subset of data points from a given tensor.</p>
<p>This is useful for creating smaller, representative datasets for tasks such as
evaluating model performance on a subset of the data or for visualization purposes.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor from which to sample.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>n_samples</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of data points to sample from the tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A new tensor containing the sampled data points.
The sampled data maintains the original data's structure while reducing its size,
which is important for efficient analysis and evaluation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_from_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Samples a subset of data points from a given tensor.</span>

<span class="sd">    This is useful for creating smaller, representative datasets for tasks such as</span>
<span class="sd">    evaluating model performance on a subset of the data or for visualization purposes.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (torch.Tensor): The input tensor from which to sample.</span>
<span class="sd">        n_samples (int): The number of data points to sample from the tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A new tensor containing the sampled data points.</span>
<span class="sd">            The sampled data maintains the original data&#39;s structure while reducing its size,</span>
<span class="sd">            which is important for efficient analysis and evaluation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">indices_trunc</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
    <span class="n">sampled_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">indices_trunc</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">sampled_tensor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.total_grad_norm" class="doc doc-heading">
            <code class=" language-python"><span class="n">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.training.TrainerModified.total_grad_norm" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the total gradient norm of a model's parameters.</p>
<p>Calculates the L2 norm of the gradients across all parameters in the model.
This is useful for monitoring training and detecting potential issues like
exploding gradients, ensuring stable training during synthetic data generation.
By monitoring the gradient norm, we can ensure the generator and discriminator
are learning effectively and preventing mode collapse, which is crucial for
producing high-quality synthetic data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model whose gradients are to be analyzed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>float</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The total gradient norm.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">total_grad_norm</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the total gradient norm of a model&#39;s parameters.</span>

<span class="sd">    Calculates the L2 norm of the gradients across all parameters in the model.</span>
<span class="sd">    This is useful for monitoring training and detecting potential issues like</span>
<span class="sd">    exploding gradients, ensuring stable training during synthetic data generation.</span>
<span class="sd">    By monitoring the gradient norm, we can ensure the generator and discriminator</span>
<span class="sd">    are learning effectively and preventing mode collapse, which is crucial for</span>
<span class="sd">    producing high-quality synthetic data.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The model whose gradients are to be analyzed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The total gradient norm.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">total_norm</span><span class="o">**</span><span class="mf">0.5</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.train" class="doc doc-heading">
            <code class=" language-python"><span class="n">train</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.train" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Trains the GAN model to generate synthetic data that mimics the statistical properties of the real data.</p>
<p>The training process involves updating the generator and discriminator networks iteratively
to improve the quality and utility of the generated samples. The method also tracks
various metrics and visualizations to monitor the training progress and evaluate the
performance of the GAN.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>data_loader</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data loader providing batches of real data for training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epochs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of training epochs to perform.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>plot_freq</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The frequency (in epochs) at which to generate and track plots for
monitoring training progress.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None. The method trains the GAN model in place, updating the generator and
discriminator networks.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">plot_freq</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains the GAN model to generate synthetic data that mimics the statistical properties of the real data.</span>

<span class="sd">    The training process involves updating the generator and discriminator networks iteratively</span>
<span class="sd">    to improve the quality and utility of the generated samples. The method also tracks</span>
<span class="sd">    various metrics and visualizations to monitor the training progress and evaluate the</span>
<span class="sd">    performance of the GAN.</span>

<span class="sd">    Args:</span>
<span class="sd">        data_loader: The data loader providing batches of real data for training.</span>
<span class="sd">        epochs: The number of training epochs to perform.</span>
<span class="sd">        plot_freq: The frequency (in epochs) at which to generate and track plots for</span>
<span class="sd">            monitoring training progress.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None. The method trains the GAN model in place, updating the generator and</span>
<span class="sd">            discriminator networks.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mfs_manager</span><span class="o">.</span><span class="n">change_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">disable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_values</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">real_data_sample</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span>
        <span class="c1"># samples = [self.sample_generator(self.batch_size) for _ in range(self.sample_number)]</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_generator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mfs_loss</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss MFS&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_G&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_grad_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;total_norm_D&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">GP_grad_norm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;GP_grad_norm&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">samples</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">real_data_sample</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">real_data_sample</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Synthetic&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                <span class="n">real_data_sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Real data&quot;</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">pca</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explained var: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

            <span class="n">aim_fig</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;progress&quot;</span><span class="p">)</span>
            <span class="c1"># fig = plt.figure()</span>
            <span class="c1"># plt.scatter(samples[0].cpu().detach().numpy()[:, 0], samples[0].cpu().detach().numpy()[:, 1],</span>
            <span class="c1">#             label=&quot;Synthetic&quot;, alpha=0.2)</span>
            <span class="c1"># plt.scatter(real_data_sample[:, 0], real_data_sample[:, 1],</span>
            <span class="c1">#             label=&quot;Real data&quot;, alpha=0.2)</span>
            <span class="c1">#</span>
            <span class="c1"># plt.legend()</span>
            <span class="c1"># plt.close(fig)</span>

            <span class="c1"># aim_fig = Image(fig)</span>
            <span class="c1"># self.aim_track.track(aim_fig, epoch=epoch, name=&quot;progress&quot;)</span>

            <span class="n">fig_G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_grad_flow</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;G gradient flow&quot;</span>
            <span class="p">)</span>
            <span class="n">fig_D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_grad_flow</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;D gradient flow&quot;</span>
            <span class="p">)</span>

            <span class="c1"># fig_mfs_distr = self.plot_qq_plot(</span>
            <span class="c1">#     mfs_batch=np.asarray([self.calculate_mfs_torch(X).cpu().detach().numpy() for X in samples]))</span>

            <span class="n">aim_fig_G</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig_G</span><span class="p">)</span>
            <span class="n">aim_fig_D</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">fig_D</span><span class="p">)</span>
            <span class="c1"># aim_fig_mfs_distr = Image(fig_mfs_distr)</span>

            <span class="c1"># self.aim_track.track(aim_fig_mfs_distr, epoch=epoch, name=&quot;qq plot&quot;)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig_G</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;G grad flow&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">aim_track</span><span class="o">.</span><span class="n">track</span><span class="p">(</span><span class="n">aim_fig_D</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;D grad flow&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.wasserstein_distance_2d" class="doc doc-heading">
            <code class=" language-python"><span class="n">wasserstein_distance_2d</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.wasserstein_distance_2d" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Compute the Wasserstein distance between two 2D point clouds.</p>
<p>This method calculates the Earth Mover's Distance (EMD), also known as the
Wasserstein distance, between two sets of 2D points. It assumes that both
point clouds have equal weights assigned to each point. This distance is used
to evaluate how well the generated data distribution matches the real data
distribution, ensuring the synthetic data retains statistical similarity.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x1</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The first point cloud, represented as a batch of 2D points.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x2</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The second point cloud, represented as a batch of 2D points.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>float</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Wasserstein distance between the two point clouds.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">wasserstein_distance_2d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Wasserstein distance between two 2D point clouds.</span>

<span class="sd">    This method calculates the Earth Mover&#39;s Distance (EMD), also known as the</span>
<span class="sd">    Wasserstein distance, between two sets of 2D points. It assumes that both</span>
<span class="sd">    point clouds have equal weights assigned to each point. This distance is used</span>
<span class="sd">    to evaluate how well the generated data distribution matches the real data</span>
<span class="sd">    distribution, ensuring the synthetic data retains statistical similarity.</span>

<span class="sd">    Args:</span>
<span class="sd">        x1 (torch.Tensor): The first point cloud, represented as a batch of 2D points.</span>
<span class="sd">        x2 (torch.Tensor): The second point cloud, represented as a batch of 2D points.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The Wasserstein distance between the two point clouds.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">ab</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>
    <span class="n">ab</span> <span class="o">=</span> <span class="n">ab</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">M</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ot</span><span class="o">.</span><span class="n">emd2</span><span class="p">(</span><span class="n">ab</span><span class="p">,</span> <span class="n">ab</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.training.TrainerModified.wasserstein_loss_mfs" class="doc doc-heading">
            <code class=" language-python"><span class="n">wasserstein_loss_mfs</span><span class="p">(</span><span class="n">mfs1</span><span class="p">,</span> <span class="n">mfs2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#wgan_gp.training.TrainerModified.wasserstein_loss_mfs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the Wasserstein loss between two sets of meta-feature statistics (MFS).</p>
<p>This method quantifies the statistical similarity between the real and synthetic
data distributions by computing the Wasserstein distance between corresponding
feature pairs in the input MFS sets. This loss is used to train the generator
to produce synthetic data that closely matches the statistical properties of
the real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mfs1</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The first set of meta-feature statistics, representing
the real data distribution.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mfs2</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The second set of meta-feature statistics, representing
the synthetic data distribution.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>average</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A boolean indicating whether to return the average
loss (True) or a tensor of individual losses (False). Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor or float: If <code>average</code> is True, returns the average
Wasserstein loss as a float. Otherwise, returns a tensor containing the
individual Wasserstein distances for each feature.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/training.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">wasserstein_loss_mfs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mfs1</span><span class="p">,</span> <span class="n">mfs2</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the Wasserstein loss between two sets of meta-feature statistics (MFS).</span>

<span class="sd">    This method quantifies the statistical similarity between the real and synthetic</span>
<span class="sd">    data distributions by computing the Wasserstein distance between corresponding</span>
<span class="sd">    feature pairs in the input MFS sets. This loss is used to train the generator</span>
<span class="sd">    to produce synthetic data that closely matches the statistical properties of</span>
<span class="sd">    the real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        mfs1 (torch.Tensor): The first set of meta-feature statistics, representing</span>
<span class="sd">            the real data distribution.</span>
<span class="sd">        mfs2 (torch.Tensor): The second set of meta-feature statistics, representing</span>
<span class="sd">            the synthetic data distribution.</span>
<span class="sd">        average (bool, optional): A boolean indicating whether to return the average</span>
<span class="sd">            loss (True) or a tensor of individual losses (False). Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor or float: If `average` is True, returns the average</span>
<span class="sd">            Wasserstein loss as a float. Otherwise, returns a tensor containing the</span>
<span class="sd">            individual Wasserstein distances for each feature.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># total = 0</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">mfs1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">wsds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mfs1</span><span class="p">,</span> <span class="n">mfs2</span><span class="p">):</span>
        <span class="n">wsd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wasserstein_distance_2d</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">second</span><span class="p">)</span>
        <span class="n">wsds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wsd</span><span class="p">)</span>
        <span class="c1"># total += wsd</span>

    <span class="c1"># print_debug = [[i, j.cpu().detach()] for i, j in zip(self.subset_mfs, wsds)]</span>
    <span class="c1"># print(*print_debug,</span>
    <span class="c1">#       sep=&#39;\n&#39;)</span>
    <span class="k">if</span> <span class="n">average</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">wsds</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_features</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">wsds</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>