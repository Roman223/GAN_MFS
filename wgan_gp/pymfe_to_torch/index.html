
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="WGAN-GP with Meta-Feature Statistics for Synthetic Tabular Data Generation">
      
      
      
      
        <link rel="prev" href="../training/">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>PyMFE to Torch - GAN_MFS Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-blue" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pymfe-to-torch-module" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="GAN_MFS Documentation" class="md-header__button md-logo" aria-label="GAN_MFS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GAN_MFS Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              PyMFE to Torch
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-blue" data-md-color-accent="blue"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../utils/" class="md-tabs__link">
        
  
  
    
  
  Utils

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  WGAN-GP

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="GAN_MFS Documentation" class="md-nav__button md-logo" aria-label="GAN_MFS Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    GAN_MFS Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    WGAN-GP
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            WGAN-GP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    PyMFE to Torch
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    PyMFE to Torch
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statistical-meta-features" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Meta-Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-integration" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mfetotorch-class" class="md-nav__link">
    <span class="md-ellipsis">
      MFEToTorch Class
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usage-in-training" class="md-nav__link">
    <span class="md-ellipsis">
      Usage in Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch" class="md-nav__link">
    <span class="md-ellipsis">
      pymfe_to_torch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="pymfe_to_torch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch" class="md-nav__link">
    <span class="md-ellipsis">
      MFEToTorch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MFEToTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.feature_methods" class="md-nav__link">
    <span class="md-ellipsis">
      feature_methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.change_device" class="md-nav__link">
    <span class="md-ellipsis">
      change_device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.corrcoef" class="md-nav__link">
    <span class="md-ellipsis">
      corrcoef
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.cov" class="md-nav__link">
    <span class="md-ellipsis">
      cov
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cor_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_cor_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cov_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_cov_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_eigenvals" class="md-nav__link">
    <span class="md-ellipsis">
      ft_eigenvals
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_gravity_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_gravity_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_iq_range" class="md-nav__link">
    <span class="md-ellipsis">
      ft_iq_range
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_kurtosis" class="md-nav__link">
    <span class="md-ellipsis">
      ft_kurtosis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mad" class="md-nav__link">
    <span class="md-ellipsis">
      ft_mad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_max" class="md-nav__link">
    <span class="md-ellipsis">
      ft_max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mean" class="md-nav__link">
    <span class="md-ellipsis">
      ft_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_median" class="md-nav__link">
    <span class="md-ellipsis">
      ft_median
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_min" class="md-nav__link">
    <span class="md-ellipsis">
      ft_min
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_range" class="md-nav__link">
    <span class="md-ellipsis">
      ft_range
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_skewness" class="md-nav__link">
    <span class="md-ellipsis">
      ft_skewness
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_sparsity" class="md-nav__link">
    <span class="md-ellipsis">
      ft_sparsity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_std" class="md-nav__link">
    <span class="md-ellipsis">
      ft_std
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_var" class="md-nav__link">
    <span class="md-ellipsis">
      ft_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.get_mfs" class="md-nav__link">
    <span class="md-ellipsis">
      get_mfs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.pad_only" class="md-nav__link">
    <span class="md-ellipsis">
      pad_only
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.test_me" class="md-nav__link">
    <span class="md-ellipsis">
      test_me
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-features" class="md-nav__link">
    <span class="md-ellipsis">
      Key Features
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Features">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statistical-meta-features" class="md-nav__link">
    <span class="md-ellipsis">
      Statistical Meta-Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-integration" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mfetotorch-class" class="md-nav__link">
    <span class="md-ellipsis">
      MFEToTorch Class
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usage-in-training" class="md-nav__link">
    <span class="md-ellipsis">
      Usage in Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch" class="md-nav__link">
    <span class="md-ellipsis">
      pymfe_to_torch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="pymfe_to_torch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch" class="md-nav__link">
    <span class="md-ellipsis">
      MFEToTorch
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MFEToTorch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.feature_methods" class="md-nav__link">
    <span class="md-ellipsis">
      feature_methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.change_device" class="md-nav__link">
    <span class="md-ellipsis">
      change_device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.corrcoef" class="md-nav__link">
    <span class="md-ellipsis">
      corrcoef
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.cov" class="md-nav__link">
    <span class="md-ellipsis">
      cov
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cor_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_cor_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cov_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_cov_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_eigenvals" class="md-nav__link">
    <span class="md-ellipsis">
      ft_eigenvals
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_gravity_torch" class="md-nav__link">
    <span class="md-ellipsis">
      ft_gravity_torch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_iq_range" class="md-nav__link">
    <span class="md-ellipsis">
      ft_iq_range
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_kurtosis" class="md-nav__link">
    <span class="md-ellipsis">
      ft_kurtosis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mad" class="md-nav__link">
    <span class="md-ellipsis">
      ft_mad
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_max" class="md-nav__link">
    <span class="md-ellipsis">
      ft_max
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mean" class="md-nav__link">
    <span class="md-ellipsis">
      ft_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_median" class="md-nav__link">
    <span class="md-ellipsis">
      ft_median
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_min" class="md-nav__link">
    <span class="md-ellipsis">
      ft_min
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_range" class="md-nav__link">
    <span class="md-ellipsis">
      ft_range
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_skewness" class="md-nav__link">
    <span class="md-ellipsis">
      ft_skewness
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_sparsity" class="md-nav__link">
    <span class="md-ellipsis">
      ft_sparsity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_std" class="md-nav__link">
    <span class="md-ellipsis">
      ft_std
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_var" class="md-nav__link">
    <span class="md-ellipsis">
      ft_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.get_mfs" class="md-nav__link">
    <span class="md-ellipsis">
      get_mfs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.pad_only" class="md-nav__link">
    <span class="md-ellipsis">
      pad_only
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wgan_gp.pymfe_to_torch.MFEToTorch.test_me" class="md-nav__link">
    <span class="md-ellipsis">
      test_me
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="pymfe-to-torch-module">PyMFE to Torch Module<a class="headerlink" href="#pymfe-to-torch-module" title="Permanent link">&para;</a></h1>
<p>This module provides a PyTorch implementation of Meta-Feature Extraction (MFE) for statistical analysis of tabular data.</p>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>The PyMFE to Torch module converts meta-feature extraction operations into PyTorch tensors, enabling differentiable computation of statistical properties during GAN training. This is essential for the Meta-Feature Statistics (MFS) preservation component of the WGAN-GP implementation.</p>
<h2 id="key-features">Key Features<a class="headerlink" href="#key-features" title="Permanent link">&para;</a></h2>
<h3 id="statistical-meta-features">Statistical Meta-Features<a class="headerlink" href="#statistical-meta-features" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Correlation</strong>: Pearson correlation coefficients between features</li>
<li><strong>Covariance</strong>: Covariance matrix computation</li>
<li><strong>Eigenvalues</strong>: Principal component eigenvalues for dimensionality analysis</li>
<li><strong>Distributional Statistics</strong>: Mean, variance, standard deviation, range, min, max</li>
<li><strong>Advanced Statistics</strong>: Skewness, kurtosis, interquartile range, sparsity</li>
</ul>
<h3 id="pytorch-integration">PyTorch Integration<a class="headerlink" href="#pytorch-integration" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Differentiable Operations</strong>: All computations maintain gradient flow</li>
<li><strong>GPU Acceleration</strong>: CUDA-compatible tensor operations</li>
<li><strong>Batch Processing</strong>: Efficient computation over data batches</li>
<li><strong>Device Management</strong>: Automatic device placement for tensors</li>
</ul>
<h3 id="mfetotorch-class">MFEToTorch Class<a class="headerlink" href="#mfetotorch-class" title="Permanent link">&para;</a></h3>
<p>The main class that provides:
- Feature method mapping for easy access to statistical functions
- Torch-native implementations of traditional meta-feature extraction
- Integration with the training loop for real-time MFS computation
- Support for subset feature selection for targeted preservation</p>
<h2 id="usage-in-training">Usage in Training<a class="headerlink" href="#usage-in-training" title="Permanent link">&para;</a></h2>
<p>This module is crucial for the MFS-enhanced WGAN-GP training, where it:
1. Computes meta-features for real data variates
2. Calculates corresponding features for generated synthetic data
3. Enables Wasserstein distance computation between feature distributions
4. Provides gradients for generator optimization</p>


<div class="doc doc-object doc-module">



<h2 id="wgan_gp.pymfe_to_torch" class="doc doc-heading">
            <code>wgan_gp.pymfe_to_torch</code>


<a href="#wgan_gp.pymfe_to_torch" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">










  <div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="wgan_gp.pymfe_to_torch.MFEToTorch" class="doc doc-heading">
            <code>MFEToTorch</code>


<a href="#wgan_gp.pymfe_to_torch.MFEToTorch" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


        <p>A class to compute meta-features using PyTorch.</p>
<p>This class provides methods to calculate various meta-features for a given
dataset using PyTorch tensors. It includes functionalities for computing
statistical measures, correlation, covariance, and other properties of the
data.</p>
<p>Meta-Feature Statistics (MFS) Available:</p>
<table>
<thead>
<tr>
<th>Feature Name</th>
<th>Method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>cor</code></td>
<td><code>ft_cor_torch</code></td>
<td>Correlation matrix (absolute values of lower triangle)</td>
</tr>
<tr>
<td><code>cov</code></td>
<td><code>ft_cov_torch</code></td>
<td>Covariance matrix (absolute values of lower triangle)</td>
</tr>
<tr>
<td><code>eigenvalues</code></td>
<td><code>ft_eigenvals</code></td>
<td>Eigenvalues of the covariance matrix</td>
</tr>
<tr>
<td><code>iq_range</code></td>
<td><code>ft_iq_range</code></td>
<td>Interquartile range (Q3 - Q1)</td>
</tr>
<tr>
<td><code>gravity</code></td>
<td><code>ft_gravity_torch</code></td>
<td>Distance between majority and minority class centers</td>
</tr>
<tr>
<td><code>kurtosis</code></td>
<td><code>ft_kurtosis</code></td>
<td>Fourth moment about the mean (tailedness)</td>
</tr>
<tr>
<td><code>skewness</code></td>
<td><code>ft_skewness</code></td>
<td>Third moment about the mean (asymmetry)</td>
</tr>
<tr>
<td><code>mad</code></td>
<td><code>ft_mad</code></td>
<td>Median Absolute Deviation</td>
</tr>
<tr>
<td><code>max</code></td>
<td><code>ft_max</code></td>
<td>Maximum values along dimension 0</td>
</tr>
<tr>
<td><code>min</code></td>
<td><code>ft_min</code></td>
<td>Minimum values along dimension 0</td>
</tr>
<tr>
<td><code>mean</code></td>
<td><code>ft_mean</code></td>
<td>Mean values along dimension 0</td>
</tr>
<tr>
<td><code>median</code></td>
<td><code>ft_median</code></td>
<td>Median values along dimension 0</td>
</tr>
<tr>
<td><code>range</code></td>
<td><code>ft_range</code></td>
<td>Range (max - min) along dimension 0</td>
</tr>
<tr>
<td><code>sd</code></td>
<td><code>ft_std</code></td>
<td>Standard deviation along dimension 0</td>
</tr>
<tr>
<td><code>var</code></td>
<td><code>ft_var</code></td>
<td>Variance along dimension 0</td>
</tr>
<tr>
<td><code>sparsity</code></td>
<td><code>ft_sparsity</code></td>
<td>Feature sparsity (diversity of unique values)</td>
</tr>
</tbody>
</table>


<details class="usage" open>
  <summary>Usage</summary>
  <p>The class can be used to extract meta-features from datasets for GAN training
with Meta-Feature Statistics preservation. Common subsets include:</p>
<ul>
<li>Basic statistics: <code>['mean', 'var', 'sd']</code></li>
<li>Distribution properties: <code>['skewness', 'kurtosis', 'mad']</code></li>
<li>Relationships: <code>['cor', 'cov', 'eigenvalues']</code></li>
<li>Range measures: <code>['min', 'max', 'range', 'iq_range']</code></li>
<li>Classification features: <code>['gravity']</code> (requires target variable)</li>
</ul>
</details>

<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="wgan_gp.pymfe_to_torch.MFEToTorch.device">device</span></code></td>
            <td>
                  <code><span title="torch.device">device</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Device for computation (default: 'cpu')</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="quote">
                <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
                <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MFEToTorch</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to compute meta-features using PyTorch.</span>

<span class="sd">    This class provides methods to calculate various meta-features for a given</span>
<span class="sd">    dataset using PyTorch tensors. It includes functionalities for computing</span>
<span class="sd">    statistical measures, correlation, covariance, and other properties of the</span>
<span class="sd">    data.</span>

<span class="sd">    Meta-Feature Statistics (MFS) Available:</span>

<span class="sd">    | Feature Name | Method | Description |</span>
<span class="sd">    |--------------|--------|-------------|</span>
<span class="sd">    | `cor` | `ft_cor_torch` | Correlation matrix (absolute values of lower triangle) |</span>
<span class="sd">    | `cov` | `ft_cov_torch` | Covariance matrix (absolute values of lower triangle) |</span>
<span class="sd">    | `eigenvalues` | `ft_eigenvals` | Eigenvalues of the covariance matrix |</span>
<span class="sd">    | `iq_range` | `ft_iq_range` | Interquartile range (Q3 - Q1) |</span>
<span class="sd">    | `gravity` | `ft_gravity_torch` | Distance between majority and minority class centers |</span>
<span class="sd">    | `kurtosis` | `ft_kurtosis` | Fourth moment about the mean (tailedness) |</span>
<span class="sd">    | `skewness` | `ft_skewness` | Third moment about the mean (asymmetry) |</span>
<span class="sd">    | `mad` | `ft_mad` | Median Absolute Deviation |</span>
<span class="sd">    | `max` | `ft_max` | Maximum values along dimension 0 |</span>
<span class="sd">    | `min` | `ft_min` | Minimum values along dimension 0 |</span>
<span class="sd">    | `mean` | `ft_mean` | Mean values along dimension 0 |</span>
<span class="sd">    | `median` | `ft_median` | Median values along dimension 0 |</span>
<span class="sd">    | `range` | `ft_range` | Range (max - min) along dimension 0 |</span>
<span class="sd">    | `sd` | `ft_std` | Standard deviation along dimension 0 |</span>
<span class="sd">    | `var` | `ft_var` | Variance along dimension 0 |</span>
<span class="sd">    | `sparsity` | `ft_sparsity` | Feature sparsity (diversity of unique values) |</span>

<span class="sd">    Usage:</span>
<span class="sd">        The class can be used to extract meta-features from datasets for GAN training</span>
<span class="sd">        with Meta-Feature Statistics preservation. Common subsets include:</span>

<span class="sd">        - Basic statistics: `[&#39;mean&#39;, &#39;var&#39;, &#39;sd&#39;]`</span>
<span class="sd">        - Distribution properties: `[&#39;skewness&#39;, &#39;kurtosis&#39;, &#39;mad&#39;]`</span>
<span class="sd">        - Relationships: `[&#39;cor&#39;, &#39;cov&#39;, &#39;eigenvalues&#39;]`</span>
<span class="sd">        - Range measures: `[&#39;min&#39;, &#39;max&#39;, &#39;range&#39;, &#39;iq_range&#39;]`</span>
<span class="sd">        - Classification features: `[&#39;gravity&#39;]` (requires target variable)</span>

<span class="sd">    Attributes:</span>
<span class="sd">        device (torch.device): Device for computation (default: &#39;cpu&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">feature_methods</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a dictionary that maps feature names to their corresponding extraction methods.</span>

<span class="sd">        This mapping is essential for calculating a comprehensive set of statistical</span>
<span class="sd">        properties on both real and synthetic datasets. These features are then</span>
<span class="sd">        used to evaluate the quality and utility of the generated synthetic data</span>
<span class="sd">        by comparing them against the features of the real data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary where keys are feature names (strings) and</span>
<span class="sd">                values are the corresponding feature extraction methods.</span>
<span class="sd">                See the class docstring for a complete table of available features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;cor&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_cor_torch</span><span class="p">,</span>
            <span class="s2">&quot;cov&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_cov_torch</span><span class="p">,</span>
            <span class="s2">&quot;eigenvalues&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_eigenvals</span><span class="p">,</span>
            <span class="s2">&quot;iq_range&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_iq_range</span><span class="p">,</span>
            <span class="s2">&quot;gravity&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_gravity_torch</span><span class="p">,</span>
            <span class="s2">&quot;kurtosis&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_kurtosis</span><span class="p">,</span>
            <span class="s2">&quot;skewness&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_skewness</span><span class="p">,</span>
            <span class="s2">&quot;mad&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_mad</span><span class="p">,</span>
            <span class="s2">&quot;max&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_max</span><span class="p">,</span>
            <span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_min</span><span class="p">,</span>
            <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_mean</span><span class="p">,</span>
            <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_median</span><span class="p">,</span>
            <span class="s2">&quot;range&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_range</span><span class="p">,</span>
            <span class="s2">&quot;sd&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_std</span><span class="p">,</span>
            <span class="s2">&quot;var&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_var</span><span class="p">,</span>
            <span class="s2">&quot;sparsity&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ft_sparsity</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_gravity_torch</span><span class="p">(</span>
        <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">norm_ord</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">class_freqs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cls_inds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gravity between the majority and minority classes.</span>

<span class="sd">        This method calculates the distance between the mean feature vectors of the</span>
<span class="sd">        majority and minority classes. This distance serves as a measure of class</span>
<span class="sd">        separation in the feature space. By computing this &quot;gravity,&quot; the method</span>
<span class="sd">        quantifies the dissimilarity between the most and least frequent classes,</span>
<span class="sd">        providing insight into the dataset&#39;s class distribution and feature</span>
<span class="sd">        representation. This information can be valuable for assessing the quality</span>
<span class="sd">        and representativeness of generated synthetic data compared to real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N: Feature tensor of shape (num_instances, num_features).</span>
<span class="sd">            y: Target tensor of shape (num_instances,).</span>
<span class="sd">            norm_ord: Order of the norm to compute the distance (e.g., 2 for Euclidean). Defaults to 2.</span>
<span class="sd">            classes: Optional tensor of unique class labels. If None, it&#39;s computed from `y`.</span>
<span class="sd">            class_freqs: Optional tensor of class frequencies. If None, it&#39;s computed from `y`.</span>
<span class="sd">            cls_inds: Optional list of indices for each class. If provided, it uses these indices to select instances.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The gravity value, representing the distance between the class centers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">class_freqs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">classes</span><span class="p">,</span> <span class="n">class_freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">ind_cls_maj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_freqs</span><span class="p">)</span>
        <span class="n">class_maj</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">ind_cls_maj</span><span class="p">]</span>

        <span class="n">remaining_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span><span class="n">classes</span><span class="p">[:</span><span class="n">ind_cls_maj</span><span class="p">],</span> <span class="n">classes</span><span class="p">[</span><span class="n">ind_cls_maj</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:])</span>
        <span class="p">)</span>
        <span class="n">remaining_freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">(</span><span class="n">class_freqs</span><span class="p">[:</span><span class="n">ind_cls_maj</span><span class="p">],</span> <span class="n">class_freqs</span><span class="p">[</span><span class="n">ind_cls_maj</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:])</span>
        <span class="p">)</span>

        <span class="n">ind_cls_min</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">remaining_freqs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cls_inds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">insts_cls_maj</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">cls_inds</span><span class="p">[</span><span class="n">ind_cls_maj</span><span class="p">]]</span>
            <span class="k">if</span> <span class="n">ind_cls_min</span> <span class="o">&gt;=</span> <span class="n">ind_cls_maj</span><span class="p">:</span>
                <span class="n">ind_cls_min</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">insts_cls_min</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">cls_inds</span><span class="p">[</span><span class="n">ind_cls_min</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">class_min</span> <span class="o">=</span> <span class="n">remaining_classes</span><span class="p">[</span><span class="n">ind_cls_min</span><span class="p">]</span>
            <span class="n">insts_cls_maj</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">class_maj</span><span class="p">]</span>
            <span class="n">insts_cls_min</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">class_min</span><span class="p">]</span>

        <span class="n">center_maj</span> <span class="o">=</span> <span class="n">insts_cls_maj</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">center_min</span> <span class="o">=</span> <span class="n">insts_cls_min</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">gravity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">center_maj</span> <span class="o">-</span> <span class="n">center_min</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">norm_ord</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">gravity</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">change_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Changes the device where computations will be performed.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (str): The target device (e.g., &#39;cpu&#39;, &#39;cuda&#39;).</span>

<span class="sd">        This method is crucial for ensuring that the model and data reside on the same device,</span>
<span class="sd">        allowing for efficient computation and utilization of available hardware resources</span>
<span class="sd">        during the synthetic data generation and evaluation processes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">cov</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimates the covariance matrix of a given tensor, crucial for understanding the statistical relationships within the data. This is a key step in evaluating how well the generated synthetic data captures the underlying dependencies present in the original data.</span>

<span class="sd">                Args:</span>
<span class="sd">                    tensor (torch.Tensor): Input data tensor.</span>
<span class="sd">                    rowvar (bool, optional): If True (default), rows represent variables, with observations in the columns. If False, columns represent variables.</span>
<span class="sd">                    bias (bool, optional): If False (default), then the normalization is by N-1. Otherwise, normalization is by N.</span>

<span class="sd">                Returns:</span>
<span class="sd">                    torch.Tensor: The covariance matrix of the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">rowvar</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">-</span> <span class="n">tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="n">bias</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">factor</span> <span class="o">*</span> <span class="n">tensor</span> <span class="o">@</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">corrcoef</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the Pearson product-moment correlation coefficients, normalizing the covariance matrix by the standard deviations to obtain correlation values. This provides a measure of the linear relationship between variables in the input tensor, which is useful for comparing real and synthetic data.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor): Input data tensor.</span>
<span class="sd">            rowvar (bool, optional): If True (default), rows represent variables, with observations in the columns. Otherwise, columns represent variables.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Pearson product-moment correlation coefficients matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="n">rowvar</span><span class="p">)</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">covariance</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">variance</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
            <span class="n">variance</span> <span class="o">=</span> <span class="n">variance</span><span class="o">.</span><span class="n">real</span>
        <span class="n">stddev</span> <span class="o">=</span> <span class="n">variance</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">covariance</span> <span class="o">/=</span> <span class="n">stddev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">covariance</span> <span class="o">/=</span> <span class="n">stddev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">covariance</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
            <span class="n">covariance</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">covariance</span><span class="o">.</span><span class="n">imag</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">covariance</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">covariance</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ft_cor_torch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the absolute values of the lower triangle elements of a correlation matrix to quantify feature dependencies.</span>

<span class="sd">        This method computes the correlation matrix of the input tensor `N`,</span>
<span class="sd">        extracts the elements from the lower triangle (excluding the diagonal),</span>
<span class="sd">        and returns the absolute values of these elements. This is done to summarize the relationships between features,</span>
<span class="sd">        which is useful for evaluating how well the synthetic data captures the dependencies present in the real data.</span>
<span class="sd">        By focusing on the lower triangle and taking absolute values, the method efficiently provides a measure of feature interconnectedness,</span>
<span class="sd">        ignoring self-correlations and directionality.</span>

<span class="sd">        Args:</span>
<span class="sd">            N: The input tensor for which to compute the correlation matrix.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the absolute values of the elements</span>
<span class="sd">                in the lower triangle of the correlation matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">corr_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">corr_mat</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">tril_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">res_num_rows</span><span class="p">,</span> <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">inf_triang_vals</span> <span class="o">=</span> <span class="n">corr_mat</span><span class="p">[</span><span class="n">tril_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">inf_triang_vals</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ft_cov_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the absolute values of the lower triangular elements of the covariance matrix. This focuses on the relationships between variables, extracting the lower triangle to reduce redundancy and focusing on key covariance values. The absolute value ensures that the magnitude of the covariance is considered, regardless of the direction of the relationship.</span>

<span class="sd">        Args:</span>
<span class="sd">            N: Input tensor for covariance calculation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the absolute values of the lower triangular elements of the covariance matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cov_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">res_num_rows</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tril_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">res_num_rows</span><span class="p">,</span> <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">inf_triang_vals</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="p">[</span><span class="n">tril_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">inf_triang_vals</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ft_eigenvals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the eigenvalues of the covariance matrix of the input tensor.</span>

<span class="sd">        This function is crucial for assessing the diversity and information</span>
<span class="sd">        content of the input data. By calculating the eigenvalues of the</span>
<span class="sd">        covariance matrix, we gain insights into the principal components</span>
<span class="sd">        and variance distribution within the data, which helps to ensure</span>
<span class="sd">        the generated synthetic data retains the key statistical</span>
<span class="sd">        characteristics of the original data.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The eigenvalues of the covariance matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># taking real part of first two eigenvals</span>
        <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">covs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">centered</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">covs</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_iq_range</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the interquartile range (IQR) of a tensor along the first dimension.</span>

<span class="sd">        The IQR is a measure of statistical dispersion, representing the difference between the 75th and 25th percentiles. This is useful for understanding the spread of the data, which helps to assess the utility of generated synthetic data by comparing its distribution to the real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: The input tensor of shape [num_samples, num_features].</span>

<span class="sd">        Returns:</span>
<span class="sd">            The interquartile range of the input tensor, with shape [num_features]. This represents the spread of each feature across the samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">q75</span><span class="p">,</span> <span class="n">q25</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">iqr</span> <span class="o">=</span> <span class="n">q75</span> <span class="o">-</span> <span class="n">q25</span>  <span class="c1"># shape: [num_features]</span>
        <span class="k">return</span> <span class="n">iqr</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_kurtosis</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the kurtosis of a tensor.</span>

<span class="sd">        This function computes the kurtosis of the input tensor `x`, a statistical measure</span>
<span class="sd">        describing the shape of the data&#39;s distribution, specifically its tailedness.</span>
<span class="sd">        By calculating kurtosis, we can assess how well the generated data&#39;s distribution</span>
<span class="sd">        matches that of the real data, ensuring the synthetic data retains similar statistical</span>
<span class="sd">        properties. This is crucial for maintaining the utility of the generated data in downstream tasks.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The kurtosis of the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">diffs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">zscores</span> <span class="o">=</span> <span class="n">diffs</span> <span class="o">/</span> <span class="n">std</span>
        <span class="n">kurtoses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">zscores</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">))</span> <span class="o">-</span> <span class="mf">3.0</span>
        <span class="k">return</span> <span class="n">kurtoses</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_skewness</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the skewness of a tensor.</span>

<span class="sd">        This function calculates the skewness of the input tensor, a key statistical</span>
<span class="sd">        measure reflecting the asymmetry of the data distribution. Preserving this characteristic</span>
<span class="sd">        is crucial when generating synthetic data to maintain the real data&#39;s statistical properties.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The skewness of the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">diffs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">zscores</span> <span class="o">=</span> <span class="n">diffs</span> <span class="o">/</span> <span class="n">std</span>
        <span class="n">skews</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">zscores</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">skews</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_mad</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.4826</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Median Absolute Deviation (MAD) of a tensor.</span>

<span class="sd">        The MAD is a robust measure of statistical dispersion, useful for</span>
<span class="sd">        understanding the spread of data in both real and synthetic datasets.</span>
<span class="sd">        It helps assess how well the generated data captures the variability</span>
<span class="sd">        present in the original data.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: The input tensor.</span>
<span class="sd">            factor: A scaling factor to make the MAD an unbiased estimator of the</span>
<span class="sd">                standard deviation for normal data. Default is 1.4826, which</span>
<span class="sd">                applies when the data is normally distributed.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The MAD of the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">ama</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span>
        <span class="n">mama</span> <span class="o">=</span> <span class="n">ama</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="k">return</span> <span class="n">mama</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_mean</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the mean of a tensor along the first dimension to aggregate information across samples. This is useful for summarizing the central tendency of features in the generated or real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The mean of the input tensor along dimension 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_max</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Finds the maximum value in a tensor along dimension 0. This is used to identify the most prominent features across a dataset, which is crucial for maintaining data utility in generated synthetic data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the maximum values along dimension 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_median</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the median of a tensor along the first dimension. This is used to derive a representative central tendency of the data distribution, which is a crucial aspect of maintaining data utility in synthetic data generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            N: The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the median values along the first dimension.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_min</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Finds the minimum value of a tensor along dimension 0, which is useful for identifying the smallest values across different samples when comparing real and synthetic data distributions.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the minimum values along dimension 0. This represents the minimum feature values across the dataset, aiding in the comparison of feature ranges between real and synthetic datasets.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_var</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the variance of a tensor along dimension 0. This is a crucial step in assessing the statistical similarity between real and synthetic datasets generated by the GAN, ensuring that the generated data captures the variability present in the original data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The variance of the input tensor along dimension 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_std</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the standard deviation of a tensor along the first dimension (dimension 0). This is used to understand the spread or dispersion of the generated synthetic data across different samples, ensuring the generated data maintains a similar statistical distribution to the real data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): The input tensor representing a batch of generated samples.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The standard deviation of the input tensor along dimension 0, representing the standard deviation for each feature across the generated samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">ft_range</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the range of values (max - min) along the first dimension (dimension 0) of the input tensor. This is useful for understanding the spread or variability of the data along that dimension, which helps assess how well the generated data captures the characteristics of the original data.</span>

<span class="sd">        Args:</span>
<span class="sd">            N: The input tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the range (max - min) of values along dimension 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">N</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ft_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the feature sparsity of a given tensor.</span>

<span class="sd">        This method computes the sparsity of each feature in the input tensor `N`.</span>
<span class="sd">        Sparsity is defined as the ratio of the total number of instances to the</span>
<span class="sd">        number of unique values for each feature, normalized to the range [0, 1].</span>
<span class="sd">        This metric helps to assess the diversity of feature values, which is crucial</span>
<span class="sd">        for generating synthetic data that accurately reflects the statistical</span>
<span class="sd">        properties of the original dataset. By quantifying feature sparsity, we can</span>
<span class="sd">        ensure that the generated data maintains a similar level of variability</span>
<span class="sd">        as the real data, thereby preserving its utility for downstream tasks.</span>

<span class="sd">        Args:</span>
<span class="sd">            N (torch.Tensor): A tensor of shape (num_instances, num_features) representing the input data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor of shape (num_features,) containing the sparsity</span>
<span class="sd">            score for each feature, normalized to the range [0, 1]. The tensor is</span>
<span class="sd">            moved to the device specified by `self.device`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">attr</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">N</span><span class="o">.</span><span class="n">T</span><span class="p">])</span>

        <span class="n">num_inst</span> <span class="o">=</span> <span class="n">N</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">norm_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_inst</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">ans</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm_factor</span>

        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">pad_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">target_len</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pads a tensor with zeros to a specified length, ensuring consistent input sizes for subsequent processing steps. This is particularly useful when dealing with variable-length sequences that need to be batched or processed by models requiring fixed-size inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor): The input tensor to be padded.</span>
<span class="sd">            target_len (int): The desired length of the padded tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: The padded tensor, or the original tensor if its length is already greater than or equal to `target_len`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">target_len</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">target_len</span> <span class="o">-</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">padding</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">tensor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_mfs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a set of meta-features on the input data. These meta-features capture essential characteristics of the dataset, which is crucial for evaluating and ensuring the utility of synthetic data generated by GANs.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (torch.Tensor): The input data tensor.</span>
<span class="sd">            y (torch.Tensor, optional): The target variable tensor. Required if &#39;gravity&#39; is in the subset.</span>
<span class="sd">            subset (list of str, optional): A list of meta-feature names to compute. If None, defaults to [&#39;mean&#39;, &#39;var&#39;].</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: A tensor containing the computed meta-features, padded to the maximum shape among the computed features and stacked into a single tensor. This allows for consistent representation and comparison of different meta-features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]</span>

        <span class="n">mfs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">subset</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported meta-feature: &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;gravity&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Meta-feature &#39;gravity&#39; requires `y`.&quot;</span><span class="p">)</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">[</span><span class="n">name</span><span class="p">](</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],))</span>  <span class="c1"># match dimensionality</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">[</span><span class="n">name</span><span class="p">](</span><span class="n">X</span><span class="p">)</span>

            <span class="n">mfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
        <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mfs</span><span class="p">]</span>
        <span class="n">mfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_only</span><span class="p">(</span><span class="n">mf</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">shapes</span><span class="p">))</span> <span class="k">for</span> <span class="n">mf</span> <span class="ow">in</span> <span class="n">mfs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">mfs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test_me</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compares meta-feature extraction using the `pymfe` package and the `MFEToTorch` class.</span>

<span class="sd">        This method fetches the California Housing dataset, extracts meta-features using both `pymfe` and the `MFEToTorch` class, and then compares the results. This comparison helps validate the correctness and consistency of the meta-feature extraction process implemented in the `MFEToTorch` class, ensuring that it aligns with established meta-feature extraction tools.</span>

<span class="sd">        Args:</span>
<span class="sd">            subset (list, optional): A list of meta-features to extract. If None, defaults to [&quot;mean&quot;, &quot;var&quot;].</span>

<span class="sd">        Returns:</span>
<span class="sd">            pandas.DataFrame: A DataFrame containing the meta-features extracted by both `pymfe` and `MFEToTorch`, along with any discrepancies between the two.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_california_housing</span>

        <span class="n">bunch</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">bunch</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">bunch</span><span class="o">.</span><span class="n">target</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Init data shape: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">mfe</span> <span class="o">=</span> <span class="n">MFE</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="s2">&quot;statistical&quot;</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">mfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">ft</span> <span class="o">=</span> <span class="n">mfe</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

        <span class="n">pymfe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">ft</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">index</span><span class="o">=</span><span class="n">ft</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pymfe&quot;</span><span class="p">]</span>
        <span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

        <span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mfs</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">,</span> <span class="n">subset</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">mfs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;torch_mfs&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">mfs</span><span class="p">)})</span>

        <span class="n">mfs_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">subset</span>
        <span class="c1"># mfs_df = mfs_df.reindex(self.mfs_available)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">pymfe</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">mfs_df</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">round_element</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">val</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">round_element</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.feature_methods" class="doc doc-heading">
            <code class=" language-python"><span class="n">feature_methods</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.feature_methods" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Returns a dictionary that maps feature names to their corresponding extraction methods.</p>
<p>This mapping is essential for calculating a comprehensive set of statistical
properties on both real and synthetic datasets. These features are then
used to evaluate the quality and utility of the generated synthetic data
by comparing them against the features of the real data.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>dict</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary where keys are feature names (strings) and
values are the corresponding feature extraction methods.
See the class docstring for a complete table of available features.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.change_device" class="doc doc-heading">
            <code class=" language-python"><span class="n">change_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.change_device" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Changes the device where computations will be performed.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target device (e.g., 'cpu', 'cuda').</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        <p>This method is crucial for ensuring that the model and data reside on the same device,
allowing for efficient computation and utilization of available hardware resources
during the synthetic data generation and evaluation processes.</p>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">change_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Changes the device where computations will be performed.</span>

<span class="sd">    Args:</span>
<span class="sd">        device (str): The target device (e.g., &#39;cpu&#39;, &#39;cuda&#39;).</span>

<span class="sd">    This method is crucial for ensuring that the model and data reside on the same device,</span>
<span class="sd">    allowing for efficient computation and utilization of available hardware resources</span>
<span class="sd">    during the synthetic data generation and evaluation processes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.corrcoef" class="doc doc-heading">
            <code class=" language-python"><span class="n">corrcoef</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.corrcoef" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the Pearson product-moment correlation coefficients, normalizing the covariance matrix by the standard deviations to obtain correlation values. This provides a measure of the linear relationship between variables in the input tensor, which is useful for comparing real and synthetic data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input data tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>rowvar</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True (default), rows represent variables, with observations in the columns. Otherwise, columns represent variables.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: Pearson product-moment correlation coefficients matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">corrcoef</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the Pearson product-moment correlation coefficients, normalizing the covariance matrix by the standard deviations to obtain correlation values. This provides a measure of the linear relationship between variables in the input tensor, which is useful for comparing real and synthetic data.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (torch.Tensor): Input data tensor.</span>
<span class="sd">        rowvar (bool, optional): If True (default), rows represent variables, with observations in the columns. Otherwise, columns represent variables.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Pearson product-moment correlation coefficients matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="n">rowvar</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">covariance</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variance</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">variance</span><span class="o">.</span><span class="n">real</span>
    <span class="n">stddev</span> <span class="o">=</span> <span class="n">variance</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">covariance</span> <span class="o">/=</span> <span class="n">stddev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">covariance</span> <span class="o">/=</span> <span class="n">stddev</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">covariance</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
        <span class="n">covariance</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">covariance</span><span class="o">.</span><span class="n">imag</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">covariance</span><span class="o">.</span><span class="n">clip_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">covariance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.cov" class="doc doc-heading">
            <code class=" language-python"><span class="n">cov</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.cov" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Estimates the covariance matrix of a given tensor, crucial for understanding the statistical relationships within the data. This is a key step in evaluating how well the generated synthetic data captures the underlying dependencies present in the original data.</p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">Args</span><span class="p">:</span>
<span class="w">        </span><span class="n">tensor</span><span class="w"> </span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span><span class="w"> </span><span class="n">Input</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="n">tensor</span><span class="o">.</span>
<span class="w">        </span><span class="n">rowvar</span><span class="w"> </span><span class="p">(</span><span class="nb nb-Type">bool</span><span class="p">,</span><span class="w"> </span><span class="n">optional</span><span class="p">):</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">True</span><span class="w"> </span><span class="p">(</span><span class="n">default</span><span class="p">),</span><span class="w"> </span><span class="n">rows</span><span class="w"> </span><span class="n">represent</span><span class="w"> </span><span class="n">variables</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">observations</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">columns</span><span class="o">.</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">False</span><span class="p">,</span><span class="w"> </span><span class="n">columns</span><span class="w"> </span><span class="n">represent</span><span class="w"> </span><span class="n">variables</span><span class="o">.</span>
<span class="w">        </span><span class="n">bias</span><span class="w"> </span><span class="p">(</span><span class="nb nb-Type">bool</span><span class="p">,</span><span class="w"> </span><span class="n">optional</span><span class="p">):</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">False</span><span class="w"> </span><span class="p">(</span><span class="n">default</span><span class="p">),</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">normalization</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">N</span><span class="o">-</span><span class="mf">1.</span><span class="w"> </span><span class="n">Otherwise</span><span class="p">,</span><span class="w"> </span><span class="n">normalization</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">N</span><span class="o">.</span>

<span class="w">    </span><span class="n">Returns</span><span class="p">:</span>
<span class="w">        </span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">covariance</span><span class="w"> </span><span class="n">matrix</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">tensor</span><span class="o">.</span>
</code></pre></div>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cov</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimates the covariance matrix of a given tensor, crucial for understanding the statistical relationships within the data. This is a key step in evaluating how well the generated synthetic data captures the underlying dependencies present in the original data.</span>

<span class="sd">            Args:</span>
<span class="sd">                tensor (torch.Tensor): Input data tensor.</span>
<span class="sd">                rowvar (bool, optional): If True (default), rows represent variables, with observations in the columns. If False, columns represent variables.</span>
<span class="sd">                bias (bool, optional): If False (default), then the normalization is by N-1. Otherwise, normalization is by N.</span>

<span class="sd">            Returns:</span>
<span class="sd">                torch.Tensor: The covariance matrix of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">rowvar</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span> <span class="o">-</span> <span class="n">tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="n">bias</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">factor</span> <span class="o">*</span> <span class="n">tensor</span> <span class="o">@</span> <span class="n">tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">conj</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_cor_torch" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_cor_torch</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cor_torch" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the absolute values of the lower triangle elements of a correlation matrix to quantify feature dependencies.</p>
<p>This method computes the correlation matrix of the input tensor <code>N</code>,
extracts the elements from the lower triangle (excluding the diagonal),
and returns the absolute values of these elements. This is done to summarize the relationships between features,
which is useful for evaluating how well the synthetic data captures the dependencies present in the real data.
By focusing on the lower triangle and taking absolute values, the method efficiently provides a measure of feature interconnectedness,
ignoring self-correlations and directionality.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor for which to compute the correlation matrix.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the absolute values of the elements
in the lower triangle of the correlation matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">ft_cor_torch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the absolute values of the lower triangle elements of a correlation matrix to quantify feature dependencies.</span>

<span class="sd">    This method computes the correlation matrix of the input tensor `N`,</span>
<span class="sd">    extracts the elements from the lower triangle (excluding the diagonal),</span>
<span class="sd">    and returns the absolute values of these elements. This is done to summarize the relationships between features,</span>
<span class="sd">    which is useful for evaluating how well the synthetic data captures the dependencies present in the real data.</span>
<span class="sd">    By focusing on the lower triangle and taking absolute values, the method efficiently provides a measure of feature interconnectedness,</span>
<span class="sd">    ignoring self-correlations and directionality.</span>

<span class="sd">    Args:</span>
<span class="sd">        N: The input tensor for which to compute the correlation matrix.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the absolute values of the elements</span>
<span class="sd">            in the lower triangle of the correlation matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">corr_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">corr_mat</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">tril_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">res_num_rows</span><span class="p">,</span> <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">inf_triang_vals</span> <span class="o">=</span> <span class="n">corr_mat</span><span class="p">[</span><span class="n">tril_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">inf_triang_vals</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_cov_torch" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_cov_torch</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_cov_torch" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the absolute values of the lower triangular elements of the covariance matrix. This focuses on the relationships between variables, extracting the lower triangle to reduce redundancy and focusing on key covariance values. The absolute value ensures that the magnitude of the covariance is considered, regardless of the direction of the relationship.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor for covariance calculation.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the absolute values of the lower triangular elements of the covariance matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">ft_cov_torch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the absolute values of the lower triangular elements of the covariance matrix. This focuses on the relationships between variables, extracting the lower triangle to reduce redundancy and focusing on key covariance values. The absolute value ensures that the magnitude of the covariance is considered, regardless of the direction of the relationship.</span>

<span class="sd">    Args:</span>
<span class="sd">        N: Input tensor for covariance calculation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the absolute values of the lower triangular elements of the covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cov_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">res_num_rows</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tril_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">res_num_rows</span><span class="p">,</span> <span class="n">res_num_rows</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">inf_triang_vals</span> <span class="o">=</span> <span class="n">cov_mat</span><span class="p">[</span><span class="n">tril_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tril_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">inf_triang_vals</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_eigenvals" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_eigenvals</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_eigenvals" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the eigenvalues of the covariance matrix of the input tensor.</p>
<p>This function is crucial for assessing the diversity and information
content of the input data. By calculating the eigenvalues of the
covariance matrix, we gain insights into the principal components
and variance distribution within the data, which helps to ensure
the generated synthetic data retains the key statistical
characteristics of the original data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The eigenvalues of the covariance matrix.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">ft_eigenvals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the eigenvalues of the covariance matrix of the input tensor.</span>

<span class="sd">    This function is crucial for assessing the diversity and information</span>
<span class="sd">    content of the input data. By calculating the eigenvalues of the</span>
<span class="sd">    covariance matrix, we gain insights into the principal components</span>
<span class="sd">    and variance distribution within the data, which helps to ensure</span>
<span class="sd">    the generated synthetic data retains the key statistical</span>
<span class="sd">    characteristics of the original data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The eigenvalues of the covariance matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># taking real part of first two eigenvals</span>
    <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">covs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">centered</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">covs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_gravity_torch" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_gravity_torch</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">norm_ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_freqs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cls_inds</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_gravity_torch" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the gravity between the majority and minority classes.</p>
<p>This method calculates the distance between the mean feature vectors of the
majority and minority classes. This distance serves as a measure of class
separation in the feature space. By computing this "gravity," the method
quantifies the dissimilarity between the most and least frequent classes,
providing insight into the dataset's class distribution and feature
representation. This information can be valuable for assessing the quality
and representativeness of generated synthetic data compared to real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Feature tensor of shape (num_instances, num_features).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target tensor of shape (num_instances,).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>norm_ord</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Order of the norm to compute the distance (e.g., 2 for Euclidean). Defaults to 2.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>classes</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional tensor of unique class labels. If None, it's computed from <code>y</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>class_freqs</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional tensor of class frequencies. If None, it's computed from <code>y</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cls_inds</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional list of indices for each class. If provided, it uses these indices to select instances.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The gravity value, representing the distance between the class centers.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_gravity_torch</span><span class="p">(</span>
    <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">norm_ord</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">class_freqs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cls_inds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the gravity between the majority and minority classes.</span>

<span class="sd">    This method calculates the distance between the mean feature vectors of the</span>
<span class="sd">    majority and minority classes. This distance serves as a measure of class</span>
<span class="sd">    separation in the feature space. By computing this &quot;gravity,&quot; the method</span>
<span class="sd">    quantifies the dissimilarity between the most and least frequent classes,</span>
<span class="sd">    providing insight into the dataset&#39;s class distribution and feature</span>
<span class="sd">    representation. This information can be valuable for assessing the quality</span>
<span class="sd">    and representativeness of generated synthetic data compared to real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N: Feature tensor of shape (num_instances, num_features).</span>
<span class="sd">        y: Target tensor of shape (num_instances,).</span>
<span class="sd">        norm_ord: Order of the norm to compute the distance (e.g., 2 for Euclidean). Defaults to 2.</span>
<span class="sd">        classes: Optional tensor of unique class labels. If None, it&#39;s computed from `y`.</span>
<span class="sd">        class_freqs: Optional tensor of class frequencies. If None, it&#39;s computed from `y`.</span>
<span class="sd">        cls_inds: Optional list of indices for each class. If provided, it uses these indices to select instances.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The gravity value, representing the distance between the class centers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">classes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">class_freqs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classes</span><span class="p">,</span> <span class="n">class_freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">ind_cls_maj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_freqs</span><span class="p">)</span>
    <span class="n">class_maj</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">ind_cls_maj</span><span class="p">]</span>

    <span class="n">remaining_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
        <span class="p">(</span><span class="n">classes</span><span class="p">[:</span><span class="n">ind_cls_maj</span><span class="p">],</span> <span class="n">classes</span><span class="p">[</span><span class="n">ind_cls_maj</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:])</span>
    <span class="p">)</span>
    <span class="n">remaining_freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
        <span class="p">(</span><span class="n">class_freqs</span><span class="p">[:</span><span class="n">ind_cls_maj</span><span class="p">],</span> <span class="n">class_freqs</span><span class="p">[</span><span class="n">ind_cls_maj</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:])</span>
    <span class="p">)</span>

    <span class="n">ind_cls_min</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">remaining_freqs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cls_inds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">insts_cls_maj</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">cls_inds</span><span class="p">[</span><span class="n">ind_cls_maj</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">ind_cls_min</span> <span class="o">&gt;=</span> <span class="n">ind_cls_maj</span><span class="p">:</span>
            <span class="n">ind_cls_min</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">insts_cls_min</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">cls_inds</span><span class="p">[</span><span class="n">ind_cls_min</span><span class="p">]]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">class_min</span> <span class="o">=</span> <span class="n">remaining_classes</span><span class="p">[</span><span class="n">ind_cls_min</span><span class="p">]</span>
        <span class="n">insts_cls_maj</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">class_maj</span><span class="p">]</span>
        <span class="n">insts_cls_min</span> <span class="o">=</span> <span class="n">N</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">class_min</span><span class="p">]</span>

    <span class="n">center_maj</span> <span class="o">=</span> <span class="n">insts_cls_maj</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">center_min</span> <span class="o">=</span> <span class="n">insts_cls_min</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">gravity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">center_maj</span> <span class="o">-</span> <span class="n">center_min</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">norm_ord</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">gravity</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_iq_range" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_iq_range</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_iq_range" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the interquartile range (IQR) of a tensor along the first dimension.</p>
<p>The IQR is a measure of statistical dispersion, representing the difference between the 75th and 25th percentiles. This is useful for understanding the spread of the data, which helps to assess the utility of generated synthetic data by comparing its distribution to the real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor of shape [num_samples, num_features].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The interquartile range of the input tensor, with shape [num_features]. This represents the spread of each feature across the samples.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_iq_range</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the interquartile range (IQR) of a tensor along the first dimension.</span>

<span class="sd">    The IQR is a measure of statistical dispersion, representing the difference between the 75th and 25th percentiles. This is useful for understanding the spread of the data, which helps to assess the utility of generated synthetic data by comparing its distribution to the real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: The input tensor of shape [num_samples, num_features].</span>

<span class="sd">    Returns:</span>
<span class="sd">        The interquartile range of the input tensor, with shape [num_features]. This represents the spread of each feature across the samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">q75</span><span class="p">,</span> <span class="n">q25</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">iqr</span> <span class="o">=</span> <span class="n">q75</span> <span class="o">-</span> <span class="n">q25</span>  <span class="c1"># shape: [num_features]</span>
    <span class="k">return</span> <span class="n">iqr</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_kurtosis" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_kurtosis</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_kurtosis" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the kurtosis of a tensor.</p>
<p>This function computes the kurtosis of the input tensor <code>x</code>, a statistical measure
describing the shape of the data's distribution, specifically its tailedness.
By calculating kurtosis, we can assess how well the generated data's distribution
matches that of the real data, ensuring the synthetic data retains similar statistical
properties. This is crucial for maintaining the utility of the generated data in downstream tasks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The kurtosis of the input tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_kurtosis</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the kurtosis of a tensor.</span>

<span class="sd">    This function computes the kurtosis of the input tensor `x`, a statistical measure</span>
<span class="sd">    describing the shape of the data&#39;s distribution, specifically its tailedness.</span>
<span class="sd">    By calculating kurtosis, we can assess how well the generated data&#39;s distribution</span>
<span class="sd">    matches that of the real data, ensuring the synthetic data retains similar statistical</span>
<span class="sd">    properties. This is crucial for maintaining the utility of the generated data in downstream tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): Input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The kurtosis of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">zscores</span> <span class="o">=</span> <span class="n">diffs</span> <span class="o">/</span> <span class="n">std</span>
    <span class="n">kurtoses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">zscores</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">))</span> <span class="o">-</span> <span class="mf">3.0</span>
    <span class="k">return</span> <span class="n">kurtoses</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_mad" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_mad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">1.4826</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mad" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Compute the Median Absolute Deviation (MAD) of a tensor.</p>
<p>The MAD is a robust measure of statistical dispersion, useful for
understanding the spread of data in both real and synthetic datasets.
It helps assess how well the generated data captures the variability
present in the original data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>factor</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A scaling factor to make the MAD an unbiased estimator of the
standard deviation for normal data. Default is 1.4826, which
applies when the data is normally distributed.</p>
              </div>
            </td>
            <td>
                  <code>1.4826</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The MAD of the input tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_mad</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.4826</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Median Absolute Deviation (MAD) of a tensor.</span>

<span class="sd">    The MAD is a robust measure of statistical dispersion, useful for</span>
<span class="sd">    understanding the spread of data in both real and synthetic datasets.</span>
<span class="sd">    It helps assess how well the generated data captures the variability</span>
<span class="sd">    present in the original data.</span>

<span class="sd">    Args:</span>
<span class="sd">        x: The input tensor.</span>
<span class="sd">        factor: A scaling factor to make the MAD an unbiased estimator of the</span>
<span class="sd">            standard deviation for normal data. Default is 1.4826, which</span>
<span class="sd">            applies when the data is normally distributed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The MAD of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="n">ama</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span>
    <span class="n">mama</span> <span class="o">=</span> <span class="n">ama</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="n">mama</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">factor</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_max" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_max</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_max" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Finds the maximum value in a tensor along dimension 0. This is used to identify the most prominent features across a dataset, which is crucial for maintaining data utility in generated synthetic data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the maximum values along dimension 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_max</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds the maximum value in a tensor along dimension 0. This is used to identify the most prominent features across a dataset, which is crucial for maintaining data utility in generated synthetic data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the maximum values along dimension 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_mean" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_mean</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_mean" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the mean of a tensor along the first dimension to aggregate information across samples. This is useful for summarizing the central tendency of features in the generated or real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The mean of the input tensor along dimension 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_mean</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the mean of a tensor along the first dimension to aggregate information across samples. This is useful for summarizing the central tendency of features in the generated or real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The mean of the input tensor along dimension 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_median" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_median</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_median" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the median of a tensor along the first dimension. This is used to derive a representative central tendency of the data distribution, which is a crucial aspect of maintaining data utility in synthetic data generation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the median values along the first dimension.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_median</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the median of a tensor along the first dimension. This is used to derive a representative central tendency of the data distribution, which is a crucial aspect of maintaining data utility in synthetic data generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        N: The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the median values along the first dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_min" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_min</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_min" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Finds the minimum value of a tensor along dimension 0, which is useful for identifying the smallest values across different samples when comparing real and synthetic data distributions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the minimum values along dimension 0. This represents the minimum feature values across the dataset, aiding in the comparison of feature ranges between real and synthetic datasets.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_min</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Finds the minimum value of a tensor along dimension 0, which is useful for identifying the smallest values across different samples when comparing real and synthetic data distributions.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the minimum values along dimension 0. This represents the minimum feature values across the dataset, aiding in the comparison of feature ranges between real and synthetic datasets.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_range" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_range</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_range" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the range of values (max - min) along the first dimension (dimension 0) of the input tensor. This is useful for understanding the spread or variability of the data along that dimension, which helps assess how well the generated data captures the characteristics of the original data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the range (max - min) of values along dimension 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_range</span><span class="p">(</span><span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the range of values (max - min) along the first dimension (dimension 0) of the input tensor. This is useful for understanding the spread or variability of the data along that dimension, which helps assess how well the generated data captures the characteristics of the original data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N: The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the range (max - min) of values along dimension 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">N</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">N</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_skewness" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_skewness</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_skewness" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes the skewness of a tensor.</p>
<p>This function calculates the skewness of the input tensor, a key statistical
measure reflecting the asymmetry of the data distribution. Preserving this characteristic
is crucial when generating synthetic data to maintain the real data's statistical properties.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The skewness of the input tensor.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_skewness</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the skewness of a tensor.</span>

<span class="sd">    This function calculates the skewness of the input tensor, a key statistical</span>
<span class="sd">    measure reflecting the asymmetry of the data distribution. Preserving this characteristic</span>
<span class="sd">    is crucial when generating synthetic data to maintain the real data&#39;s statistical properties.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The skewness of the input tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">zscores</span> <span class="o">=</span> <span class="n">diffs</span> <span class="o">/</span> <span class="n">std</span>
    <span class="n">skews</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">zscores</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">skews</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_sparsity" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_sparsity</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_sparsity" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the feature sparsity of a given tensor.</p>
<p>This method computes the sparsity of each feature in the input tensor <code>N</code>.
Sparsity is defined as the ratio of the total number of instances to the
number of unique values for each feature, normalized to the range [0, 1].
This metric helps to assess the diversity of feature values, which is crucial
for generating synthetic data that accurately reflects the statistical
properties of the original dataset. By quantifying feature sparsity, we can
ensure that the generated data maintains a similar level of variability
as the real data, thereby preserving its utility for downstream tasks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tensor of shape (num_instances, num_features) representing the input data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor of shape (num_features,) containing the sparsity</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>score for each feature, normalized to the range [0, 1]. The tensor is</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>moved to the device specified by <code>self.device</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">ft_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the feature sparsity of a given tensor.</span>

<span class="sd">    This method computes the sparsity of each feature in the input tensor `N`.</span>
<span class="sd">    Sparsity is defined as the ratio of the total number of instances to the</span>
<span class="sd">    number of unique values for each feature, normalized to the range [0, 1].</span>
<span class="sd">    This metric helps to assess the diversity of feature values, which is crucial</span>
<span class="sd">    for generating synthetic data that accurately reflects the statistical</span>
<span class="sd">    properties of the original dataset. By quantifying feature sparsity, we can</span>
<span class="sd">    ensure that the generated data maintains a similar level of variability</span>
<span class="sd">    as the real data, thereby preserving its utility for downstream tasks.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): A tensor of shape (num_instances, num_features) representing the input data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor of shape (num_features,) containing the sparsity</span>
<span class="sd">        score for each feature, normalized to the range [0, 1]. The tensor is</span>
<span class="sd">        moved to the device specified by `self.device`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">attr</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">N</span><span class="o">.</span><span class="n">T</span><span class="p">])</span>

    <span class="n">num_inst</span> <span class="o">=</span> <span class="n">N</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">norm_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_inst</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">ans</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm_factor</span>

    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_std" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_std</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_std" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the standard deviation of a tensor along the first dimension (dimension 0). This is used to understand the spread or dispersion of the generated synthetic data across different samples, ensuring the generated data maintains a similar statistical distribution to the real data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor representing a batch of generated samples.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The standard deviation of the input tensor along dimension 0, representing the standard deviation for each feature across the generated samples.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_std</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the standard deviation of a tensor along the first dimension (dimension 0). This is used to understand the spread or dispersion of the generated synthetic data across different samples, ensuring the generated data maintains a similar statistical distribution to the real data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): The input tensor representing a batch of generated samples.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The standard deviation of the input tensor along dimension 0, representing the standard deviation for each feature across the generated samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.ft_var" class="doc doc-heading">
            <code class=" language-python"><span class="n">ft_var</span><span class="p">(</span><span class="n">N</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.ft_var" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Calculates the variance of a tensor along dimension 0. This is a crucial step in assessing the statistical similarity between real and synthetic datasets generated by the GAN, ensuring that the generated data captures the variability present in the original data.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>N</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The variance of the input tensor along dimension 0.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ft_var</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the variance of a tensor along dimension 0. This is a crucial step in assessing the statistical similarity between real and synthetic datasets generated by the GAN, ensuring that the generated data captures the variability present in the original data.</span>

<span class="sd">    Args:</span>
<span class="sd">        N (torch.Tensor): The input tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The variance of the input tensor along dimension 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.get_mfs" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_mfs</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.get_mfs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Computes a set of meta-features on the input data. These meta-features capture essential characteristics of the dataset, which is crucial for evaluating and ensuring the utility of synthetic data generated by GANs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>X</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input data tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>y</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target variable tensor. Required if 'gravity' is in the subset.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>subset</code>
            </td>
            <td>
                  <code>list of str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of meta-feature names to compute. If None, defaults to ['mean', 'var'].</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: A tensor containing the computed meta-features, padded to the maximum shape among the computed features and stacked into a single tensor. This allows for consistent representation and comparison of different meta-features.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_mfs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a set of meta-features on the input data. These meta-features capture essential characteristics of the dataset, which is crucial for evaluating and ensuring the utility of synthetic data generated by GANs.</span>

<span class="sd">    Args:</span>
<span class="sd">        X (torch.Tensor): The input data tensor.</span>
<span class="sd">        y (torch.Tensor, optional): The target variable tensor. Required if &#39;gravity&#39; is in the subset.</span>
<span class="sd">        subset (list of str, optional): A list of meta-feature names to compute. If None, defaults to [&#39;mean&#39;, &#39;var&#39;].</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: A tensor containing the computed meta-features, padded to the maximum shape among the computed features and stacked into a single tensor. This allows for consistent representation and comparison of different meta-features.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]</span>

    <span class="n">mfs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">subset</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported meta-feature: &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;gravity&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Meta-feature &#39;gravity&#39; requires `y`.&quot;</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">[</span><span class="n">name</span><span class="p">](</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],))</span>  <span class="c1"># match dimensionality</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_methods</span><span class="p">[</span><span class="n">name</span><span class="p">](</span><span class="n">X</span><span class="p">)</span>

        <span class="n">mfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mfs</span><span class="p">]</span>
    <span class="n">mfs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_only</span><span class="p">(</span><span class="n">mf</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">shapes</span><span class="p">))</span> <span class="k">for</span> <span class="n">mf</span> <span class="ow">in</span> <span class="n">mfs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">mfs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.pad_only" class="doc doc-heading">
            <code class=" language-python"><span class="n">pad_only</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">target_len</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.pad_only" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Pads a tensor with zeros to a specified length, ensuring consistent input sizes for subsequent processing steps. This is particularly useful when dealing with variable-length sequences that need to be batched or processed by models requiring fixed-size inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>tensor</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input tensor to be padded.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>target_len</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The desired length of the padded tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor: The padded tensor, or the original tensor if its length is already greater than or equal to <code>target_len</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">pad_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">target_len</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pads a tensor with zeros to a specified length, ensuring consistent input sizes for subsequent processing steps. This is particularly useful when dealing with variable-length sequences that need to be batched or processed by models requiring fixed-size inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (torch.Tensor): The input tensor to be padded.</span>
<span class="sd">        target_len (int): The desired length of the padded tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: The padded tensor, or the original tensor if its length is already greater than or equal to `target_len`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">target_len</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">target_len</span> <span class="o">-</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">padding</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">tensor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="wgan_gp.pymfe_to_torch.MFEToTorch.test_me" class="doc doc-heading">
            <code class=" language-python"><span class="n">test_me</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#wgan_gp.pymfe_to_torch.MFEToTorch.test_me" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Compares meta-feature extraction using the <code>pymfe</code> package and the <code>MFEToTorch</code> class.</p>
<p>This method fetches the California Housing dataset, extracts meta-features using both <code>pymfe</code> and the <code>MFEToTorch</code> class, and then compares the results. This comparison helps validate the correctness and consistency of the meta-feature extraction process implemented in the <code>MFEToTorch</code> class, ensuring that it aligns with established meta-feature extraction tools.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>subset</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of meta-features to extract. If None, defaults to ["mean", "var"].</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>pandas.DataFrame: A DataFrame containing the meta-features extracted by both <code>pymfe</code> and <code>MFEToTorch</code>, along with any discrepancies between the two.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>wgan_gp/pymfe_to_torch.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_me</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compares meta-feature extraction using the `pymfe` package and the `MFEToTorch` class.</span>

<span class="sd">    This method fetches the California Housing dataset, extracts meta-features using both `pymfe` and the `MFEToTorch` class, and then compares the results. This comparison helps validate the correctness and consistency of the meta-feature extraction process implemented in the `MFEToTorch` class, ensuring that it aligns with established meta-feature extraction tools.</span>

<span class="sd">    Args:</span>
<span class="sd">        subset (list, optional): A list of meta-features to extract. If None, defaults to [&quot;mean&quot;, &quot;var&quot;].</span>

<span class="sd">    Returns:</span>
<span class="sd">        pandas.DataFrame: A DataFrame containing the meta-features extracted by both `pymfe` and `MFEToTorch`, along with any discrepancies between the two.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">subset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;var&quot;</span><span class="p">]</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_california_housing</span>

    <span class="n">bunch</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">bunch</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">bunch</span><span class="o">.</span><span class="n">target</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Init data shape: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">mfe</span> <span class="o">=</span> <span class="n">MFE</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="s2">&quot;statistical&quot;</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">mfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">ft</span> <span class="o">=</span> <span class="n">mfe</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

    <span class="n">pymfe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">ft</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">index</span><span class="o">=</span><span class="n">ft</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pymfe&quot;</span><span class="p">]</span>
    <span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

    <span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">y_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="n">mfs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mfs</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">y_tensor</span><span class="p">,</span> <span class="n">subset</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">mfs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;torch_mfs&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">mfs</span><span class="p">)})</span>

    <span class="n">mfs_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">subset</span>
    <span class="c1"># mfs_df = mfs_df.reindex(self.mfs_available)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">pymfe</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">mfs_df</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">round_element</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">val</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">decimals</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">round_element</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>